<!DOCTYPE html>
<html lang="en">
<head>
        <title>Edwin Chen's Blog - misc</title>
        <meta charset="utf-8" />
	      <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <link rel="stylesheet" href="/theme/css/main.css" type="text/css" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie.css"/>
                <script src="/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie6.css"/><![endif]-->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js" type="text/javascript"></script>


</head>

<body id="index" class="home">
	
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/2012/03/05/instant-interactive-visualization-with-d3-and-ggplot2/">Instant Interactive Visualization with d3 + ggplot2</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/edwin-chen.html">Edwin Chen</a>
        </li>
        <li class="published" title="2012-03-05T04:15:00">
          on&nbsp;Mon 05 March 2012
        </li>

	</ul>

</div><!-- /.post-info -->
  <div class="entry-content"><p>It&#8217;s often easier to understand a chart than a table. So why is it still so hard to make a simple data graphic, and why am I still bombarded by mind-numbing reams of raw <em>numbers</em>?</p>

  <p>(Yeah, I love <a href="http://blog.echen.me/2012/01/17/quick-introduction-to-ggplot2/">ggplot2</a> to death. But sometimes I want a little more interaction, and sometimes all I want is to drag-and-drop and be done.)</p>

  <p>So I&#8217;ve been experimenting with <a href="http://minifolds.herokuapp.com/graphs/1?x=health&amp;y=speed&amp;size=intelligence&amp;color=age&amp;group=height">a small, ggplot2-inspired d3 app</a>.</p>

  <p>Simply drop a file, and bam! Instant scatterplot:</p>

  <p><a href="http://minifolds.herokuapp.com/graphs/1?x=health&amp;y=speed"><img src="http://dl.dropbox.com/u/10506/blog/minifolds/swiss-roll-bw.png" alt="Swiss Roll B&amp;W" /></a></p>

  <p>But wait &#8211; that&#8217;s only 2 dimensions. You can add some more through color, size, and groups:</p>

  <p><a href="http://minifolds.herokuapp.com/graphs/1?x=health&amp;y=speed&amp;size=intelligence&amp;color=age&amp;group=height"><img src="http://dl.dropbox.com/u/10506/blog/minifolds/swiss-roll-edit.png" alt="Swiss Roll Edit" /></a></p>

  <p>(Click <a href="http://minifolds.herokuapp.com/graphs/1?x=health&amp;y=speed&amp;size=intelligence&amp;color=age&amp;group=height">here</a> to play with the data yourself.)</p>

  <p>And you can easily switch which variables are getting plotted, and see all the information associated with each point.</p>

  <p><a href="http://minifolds.herokuapp.com/graphs/1?x=weight&amp;y=speed&amp;size=health&amp;color=age&amp;group=height"><img src="http://dl.dropbox.com/u/10506/blog/minifolds/swiss-roll-pivot.png" alt="Swiss Roll Pivot" /></a></p>

  <p>(Same dataset, different aesthetic assignments.)</p>

  <p>I&#8217;m thinking of adding more kinds of charts, support for categorical variables, more interactivity (sliders to interact with other dimensions?!), and making the UI even easier (e.g., simplify column naming). In the meantime, the code is <a href="https://github.com/echen/minifolds">here</a> on Github, and tips and suggestions are welcome!</p>
  </div>  

                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/2012/02/09/movie-recommendations-and-more-via-mapreduce-and-scalding/">Movie Recommendations and More via MapReduce and Scalding</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/edwin-chen.html">Edwin Chen</a>
        </li>
        <li class="published" title="2012-02-09T04:15:00">
          on&nbsp;Thu 09 February 2012
        </li>

	</ul>

</div><!-- /.post-info -->
  <div class="entry-content"><p><em>Scalding is an in-house MapReduce framework that Twitter recently open-sourced. Like <a href="http://pig.apache.org/">Pig</a>, it provides an abstraction on top of MapReduce that makes it easy to write big data jobs in a syntax that&#8217;s simple and concise. Unlike Pig, Scalding is written in pure Scala &#8211; which means all the power of Scala and the JVM is already built-in. No more UDFs, folks!</em></p>

  <p>This is going to be an in-your-face introduction to <a href="https://github.com/twitter/scalding">Scalding</a>, Twitter&#8217;s (Scala + Cascading) MapReduce framework.</p>

  <p>In 140: instead of forcing you to write raw <code>map</code> and <code>reduce</code> functions, Scalding allows you to write <em>natural</em> code like</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="c1">// Create a histogram of tweet lengths.</span>
  </span><span class="line"><span class="n">tweets</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="-Symbol">&#39;tweet</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;length</span><span class="o">)</span> <span class="o">{</span> <span class="n">tweet</span> <span class="k">:</span> <span class="kt">String</span> <span class="o">=&gt;</span> <span class="n">tweet</span><span class="o">.</span><span class="n">size</span> <span class="o">}.</span><span class="n">groupBy</span><span class="o">(</span><span class="-Symbol">&#39;length</span><span class="o">)</span> <span class="o">{</span> <span class="n">_</span><span class="o">.</span><span class="n">size</span> <span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <p>Not much different from the Ruby you&#8217;d write to compute tweet distributions over <em>small</em> data? <strong>Exactly.</strong></p>

  <p>Two notes before we begin:</p>

  <ul>
  <li><a href="https://github.com/echen/scaldingale">This Github repository</a> contains all the code used.</li>
  <li>For a gentler introduction to Scalding, see <a href="https://github.com/twitter/scalding/wiki/Getting-Started">this Getting Started guide</a> on the Scalding wiki.</li>
  </ul>


  <h1>Movie Similarities</h1>

  <p>Imagine you run an online movie business, and you want to generate movie recommendations. You have a rating system (people can rate movies with 1 to 5 stars), and we&#8217;ll assume for simplicity that all of the ratings are stored in a TSV file somewhere.</p>

  <p>Let&#8217;s start by reading the ratings into a Scalding job.</p>

  <figcaption><span>Input </span><a href="https://github.com/echen/scaldingale/blob/master/MovieSimilarities.scala">MovieSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  <span class="line-number">11</span>
  <span class="line-number">12</span>
  <span class="line-number">13</span>
  <span class="line-number">14</span>
  <span class="line-number">15</span>
  <span class="line-number">16</span>
  <span class="line-number">17</span>
  <span class="line-number">18</span>
  <span class="line-number">19</span>
  <span class="line-number">20</span>
  <span class="line-number">21</span>
  <span class="line-number">22</span>
  <span class="line-number">23</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="cm">/**</span>
  </span><span class="line"><span class="cm"> * The input is a TSV file with three columns: (user, movie, rating).</span>
  </span><span class="line"><span class="cm"> */</span>
  </span><span class="line"><span class="k">val</span> <span class="nc">INPUT_FILENAME</span> <span class="k">=</span> <span class="s">&quot;data/ratings.tsv&quot;</span>
  </span><span class="line">
  </span><span class="line"><span class="cm">/**</span>
  </span><span class="line"><span class="cm"> * Read in the input and give each field a type and name.</span>
  </span><span class="line"><span class="cm"> */</span>
  </span><span class="line"><span class="k">val</span> <span class="n">ratings</span> <span class="k">=</span> <span class="nc">Tsv</span><span class="o">(</span><span class="nc">INPUT_FILENAME</span><span class="o">,</span> <span class="o">(</span><span class="-Symbol">&#39;user</span><span class="o">,</span> <span class="-Symbol">&#39;movie</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">))</span>
  </span><span class="line">
  </span><span class="line"><span class="cm">/**</span>
  </span><span class="line"><span class="cm"> * Let&#39;s also keep track of the total number of people who rated each movie.</span>
  </span><span class="line"><span class="cm"> */</span>
  </span><span class="line"><span class="k">val</span> <span class="n">numRaters</span> <span class="k">=</span>
  </span><span class="line">  <span class="n">ratings</span>
  </span><span class="line">    <span class="c1">// Put the number of people who rated each movie into a field called &quot;numRaters&quot;.    </span>
  </span><span class="line">    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="-Symbol">&#39;movie</span><span class="o">)</span> <span class="o">{</span> <span class="n">_</span><span class="o">.</span><span class="n">size</span> <span class="o">}.</span><span class="n">rename</span><span class="o">(</span><span class="-Symbol">&#39;size</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;numRaters</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line"><span class="c1">// Merge `ratings` with `numRaters`, by joining on their movie fields.</span>
  </span><span class="line"><span class="k">val</span> <span class="n">ratingsWithSize</span> <span class="k">=</span>
  </span><span class="line">  <span class="n">ratings</span><span class="o">.</span><span class="n">joinWithSmaller</span><span class="o">(</span><span class="-Symbol">&#39;movie</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;movie</span><span class="o">,</span> <span class="n">numRaters</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line"><span class="c1">// ratingsWithSize now contains the following fields: (user, movie, rating, numRaters).</span>
  </span></code></pre></td></tr></table></div>


  <p>You want to calculate how similar pairs of movies are, so that if someone watches <em>The Lion King</em>, you can recommend films like <em>Toy Story</em>. So how should you define the similarity between two movies?</p>

  <p>One way is to use their <strong>correlation</strong>:</p>

  <ul>
  <li>For every pair of movies A and B, find all the people who rated both A and B.</li>
  <li>Use these ratings to form a Movie A vector and a Movie B vector.</li>
  <li>Calculate the correlation between these two vectors.</li>
  <li>Whenever someone watches a movie, you can then recommend the movies most correlated with it.</li>
  </ul>


  <p>Let&#8217;s start with the first two steps.</p>

  <figcaption><span>Find rating pairs </span><a href="https://github.com/echen/scaldingale/blob/master/MovieSimilarities.scala">MovieSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  <span class="line-number">11</span>
  <span class="line-number">12</span>
  <span class="line-number">13</span>
  <span class="line-number">14</span>
  <span class="line-number">15</span>
  <span class="line-number">16</span>
  <span class="line-number">17</span>
  <span class="line-number">18</span>
  <span class="line-number">19</span>
  <span class="line-number">20</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="cm">/**</span>
  </span><span class="line"><span class="cm"> * To get all pairs of co-rated movies, we&#39;ll join `ratings` against itself.</span>
  </span><span class="line"><span class="cm"> * So first make a dummy copy of the ratings that we can join against.</span>
  </span><span class="line"><span class="cm"> */</span>
  </span><span class="line"><span class="k">val</span> <span class="n">ratings2</span> <span class="k">=</span>
  </span><span class="line">  <span class="n">ratingsWithSize</span>
  </span><span class="line">    <span class="o">.</span><span class="n">rename</span><span class="o">((</span><span class="-Symbol">&#39;user</span><span class="o">,</span> <span class="-Symbol">&#39;movie</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">,</span> <span class="-Symbol">&#39;numRaters</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="-Symbol">&#39;user2</span><span class="o">,</span> <span class="-Symbol">&#39;movie2</span><span class="o">,</span> <span class="-Symbol">&#39;rating2</span><span class="o">,</span> <span class="-Symbol">&#39;numRaters2</span><span class="o">))</span>
  </span><span class="line">
  </span><span class="line"><span class="cm">/**</span>
  </span><span class="line"><span class="cm"> * Now find all pairs of co-rated movies (pairs of movies that a user has rated) by</span>
  </span><span class="line"><span class="cm"> * joining the duplicate rating streams on their user fields, </span>
  </span><span class="line"><span class="cm"> */</span>
  </span><span class="line"><span class="k">val</span> <span class="n">ratingPairs</span> <span class="k">=</span>
  </span><span class="line">  <span class="n">ratingsWithSize</span>
  </span><span class="line">    <span class="o">.</span><span class="n">joinWithSmaller</span><span class="o">(</span><span class="-Symbol">&#39;user</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;user2</span><span class="o">,</span> <span class="n">ratings2</span><span class="o">)</span>
  </span><span class="line">    <span class="c1">// De-dupe so that we don&#39;t calculate similarity of both (A, B) and (B, A).</span>
  </span><span class="line">    <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="-Symbol">&#39;movie</span><span class="o">,</span> <span class="-Symbol">&#39;movie2</span><span class="o">)</span> <span class="o">{</span> <span class="n">movies</span> <span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">movies</span><span class="o">.</span><span class="n">_1</span> <span class="o">&lt;</span> <span class="n">movies</span><span class="o">.</span><span class="n">_2</span> <span class="o">}</span>
  </span><span class="line">    <span class="o">.</span><span class="n">project</span><span class="o">(</span><span class="-Symbol">&#39;movie</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">,</span> <span class="-Symbol">&#39;numRaters</span><span class="o">,</span> <span class="-Symbol">&#39;movie2</span><span class="o">,</span> <span class="-Symbol">&#39;rating2</span><span class="o">,</span> <span class="-Symbol">&#39;numRaters2</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line"><span class="c1">// By grouping on (&#39;movie, &#39;movie2), we can now get all the people who rated any pair of movies.</span>
  </span></code></pre></td></tr></table></div>


  <p>Before using these rating pairs to calculate correlation, let&#8217;s stop for a bit.</p>

  <p>Since we&#8217;re explicitly thinking of movies as <strong>vectors</strong> of ratings, it&#8217;s natural to compute some very vector-y things like norms and dot products, as well as the length of each vector and the sum over all elements in each vector. So let&#8217;s compute these:</p>

  <figcaption><span>Vector calculations </span><a href="https://github.com/echen/scaldingale/blob/master/MovieSimilarities.scala">MovieSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  <span class="line-number">11</span>
  <span class="line-number">12</span>
  <span class="line-number">13</span>
  <span class="line-number">14</span>
  <span class="line-number">15</span>
  <span class="line-number">16</span>
  <span class="line-number">17</span>
  <span class="line-number">18</span>
  <span class="line-number">19</span>
  <span class="line-number">20</span>
  <span class="line-number">21</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="cm">/**</span>
  </span><span class="line"><span class="cm"> * Compute dot products, norms, sums, and sizes of the rating vectors.</span>
  </span><span class="line"><span class="cm"> */</span>
  </span><span class="line"><span class="k">val</span> <span class="n">vectorCalcs</span> <span class="k">=</span>
  </span><span class="line">  <span class="n">ratingPairs</span>
  </span><span class="line">    <span class="c1">// Compute (x*y, x^2, y^2), which we need for dot products and norms.</span>
  </span><span class="line">    <span class="o">.</span><span class="n">map</span><span class="o">((</span><span class="-Symbol">&#39;rating</span><span class="o">,</span> <span class="-Symbol">&#39;rating2</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="-Symbol">&#39;ratingProd</span><span class="o">,</span> <span class="-Symbol">&#39;ratingSq</span><span class="o">,</span> <span class="-Symbol">&#39;rating2Sq</span><span class="o">))</span> <span class="o">{</span>
  </span><span class="line">      <span class="n">ratings</span> <span class="k">:</span> <span class="o">(</span><span class="kt">Double</span><span class="o">,</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">=&gt;</span>
  </span><span class="line">      <span class="o">(</span><span class="n">ratings</span><span class="o">.</span><span class="n">_1</span> <span class="o">*</span> <span class="n">ratings</span><span class="o">.</span><span class="n">_2</span><span class="o">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="o">(</span><span class="n">ratings</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="o">(</span><span class="n">ratings</span><span class="o">.</span><span class="n">_2</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span>
  </span><span class="line">    <span class="o">}</span>
  </span><span class="line">    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="-Symbol">&#39;movie</span><span class="o">,</span> <span class="-Symbol">&#39;movie2</span><span class="o">)</span> <span class="o">{</span> <span class="n">group</span> <span class="k">=&gt;</span>
  </span><span class="line">        <span class="n">group</span><span class="o">.</span><span class="n">size</span> <span class="c1">// length of each vector</span>
  </span><span class="line">        <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="-Symbol">&#39;ratingProd</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;dotProduct</span><span class="o">)</span>
  </span><span class="line">        <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="-Symbol">&#39;rating</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;ratingSum</span><span class="o">)</span>
  </span><span class="line">        <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="-Symbol">&#39;rating2</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;rating2Sum</span><span class="o">)</span>
  </span><span class="line">        <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="-Symbol">&#39;ratingSq</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;ratingNormSq</span><span class="o">)</span>
  </span><span class="line">        <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="-Symbol">&#39;rating2Sq</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;rating2NormSq</span><span class="o">)</span>
  </span><span class="line">        <span class="o">.</span><span class="n">max</span><span class="o">(</span><span class="-Symbol">&#39;numRaters</span><span class="o">)</span> <span class="c1">// Just an easy way to make sure the numRaters field stays.</span>
  </span><span class="line">        <span class="o">.</span><span class="n">max</span><span class="o">(</span><span class="-Symbol">&#39;numRaters2</span><span class="o">)</span>                
  </span><span class="line">        <span class="c1">// All of these operations chain together like in a builder object.</span>
  </span><span class="line">    <span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <p>To summarize, each row in <code>vectorCalcs</code> now contains the following fields:</p>

  <ul>
  <li><strong>movie, movie2</strong></li>
  <li><strong>numRaters, numRaters2</strong>: the total number of people who rated each movie</li>
  <li><strong>size</strong>: the number of people who rated both movie and movie2</li>
  <li><strong>dotProduct</strong>: dot product between the movie vector (a vector of ratings) and the movie2 vector (also a vector of ratings)</li>
  <li><strong>ratingSum, rating2sum</strong>: sum over all elements in each ratings vector</li>
  <li><strong>ratingNormSq, rating2Normsq</strong>: squared norm of each vector</li>
  </ul>


  <p>So let&#8217;s go back to calculating the correlation between movie and movie2. We could, of course, calculate correlation in the standard way: find the covariance between the movie and movie2 ratings, and divide by their standard deviations.</p>

  <p>But recall that we can also write correlation in the following form:</p>

  <p>$Corr(X, Y) = \frac{n \sum xy - \sum x \sum y}{\sqrt{n \sum x^2 - (\sum x)^2} \sqrt{n \sum y^2 - (\sum y)^2}}$</p>

  <p>(See the <a href="http://en.wikipedia.org/wiki/Correlation_and_dependence">Wikipedia page</a> on correlation.)</p>

  <p>Notice that every one of the elements in this formula is a field in <code>vectorCalcs</code>! So instead of using the standard calculation, we can use this form instead:</p>

  <figcaption><span>Correlation </span><a href="https://github.com/echen/scaldingale/blob/master/MovieSimilarities.scala">MovieSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  <span class="line-number">11</span>
  <span class="line-number">12</span>
  <span class="line-number">13</span>
  <span class="line-number">14</span>
  <span class="line-number">15</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">val</span> <span class="n">correlations</span> <span class="k">=</span>
  </span><span class="line">  <span class="n">vectorCalcs</span>
  </span><span class="line">    <span class="o">.</span><span class="n">map</span><span class="o">((</span><span class="-Symbol">&#39;size</span><span class="o">,</span> <span class="-Symbol">&#39;dotProduct</span><span class="o">,</span> <span class="-Symbol">&#39;ratingSum</span><span class="o">,</span> <span class="-Symbol">&#39;rating2Sum</span><span class="o">,</span> <span class="-Symbol">&#39;ratingNormSq</span><span class="o">,</span> <span class="-Symbol">&#39;rating2NormSq</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="-Symbol">&#39;correlation</span><span class="o">)</span> <span class="o">{</span>
  </span><span class="line">      <span class="k">val</span> <span class="n">fields</span> <span class="k">:</span> <span class="o">(</span><span class="kt">Double</span><span class="o">,</span> <span class="kt">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">)</span> <span class="k">=&gt;</span>
  </span><span class="line">      <span class="n">correlation</span><span class="o">(</span><span class="n">fields</span><span class="o">.</span><span class="n">_1</span><span class="o">,</span> <span class="n">fields</span><span class="o">.</span><span class="n">_2</span><span class="o">,</span> <span class="n">fields</span><span class="o">.</span><span class="n">_3</span><span class="o">,</span> <span class="n">fields</span><span class="o">.</span><span class="n">_4</span><span class="o">,</span> <span class="n">fields</span><span class="o">.</span><span class="n">_5</span><span class="o">,</span> <span class="n">fields</span><span class="o">.</span><span class="n">_6</span><span class="o">)</span>
  </span><span class="line">    <span class="o">}</span>
  </span><span class="line">
  </span><span class="line"><span class="k">def</span> <span class="n">correlation</span><span class="o">(</span><span class="n">size</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">dotProduct</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">ratingSum</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span>
  </span><span class="line">  <span class="n">rating2Sum</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">ratingNormSq</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">rating2NormSq</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  </span><span class="line">
  </span><span class="line">  <span class="k">val</span> <span class="n">numerator</span> <span class="k">=</span> <span class="n">size</span> <span class="o">*</span> <span class="n">dotProduct</span> <span class="o">-</span> <span class="n">ratingSum</span> <span class="o">*</span> <span class="n">rating2Sum</span>
  </span><span class="line">  <span class="k">val</span> <span class="n">denominator</span> <span class="k">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">size</span> <span class="o">*</span> <span class="n">ratingNormSq</span> <span class="o">-</span> <span class="n">ratingSum</span> <span class="o">*</span> <span class="n">ratingSum</span><span class="o">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">size</span> <span class="o">*</span> <span class="n">rating2NormSq</span> <span class="o">-</span> <span class="n">rating2Sum</span> <span class="o">*</span> <span class="n">rating2Sum</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line">  <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
  </span><span class="line"><span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <p>And that&#8217;s it! To see the full code, check out the Github repository <a href="https://github.com/echen/scaldingale">here</a>.</p>

  <h1>Book Similarities</h1>

  <p>Let&#8217;s run this code over some real data. Unfortunately, I didn&#8217;t have a clean source of movie ratings available, so instead I used <a href="http://www.informatik.uni-freiburg.de/~cziegler/BX/">this dataset</a> of 1 million book ratings.</p>

  <p>I ran a quick command, using the handy <a href="https://github.com/twitter/scalding/wiki/Scald.rb">scald.rb script</a> that Scalding provides&#8230;</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Send the job off to a Hadoop cluster</span>
  </span><span class="line">scald.rb MovieSimilarities.scala --input ratings.tsv --output similarities.tsv
  </span></code></pre></td></tr></table></div>


  <p>&#8230;and here&#8217;s a sample of the top output I got:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/top-book-crossing-sims-correlation.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/top-book-crossing-sims-correlation.png" alt="Top Book-Crossing Pairs" /></a></p>

  <p>As we&#8217;d expect, we see that</p>

  <ul>
  <li><em>Harry Potter</em> books are similar to other <em>Harry Potter</em> books</li>
  <li><em>Lord of the Rings</em> books are similar to other <em>Lord of the Rings</em> books</li>
  <li>Tom Clancy is similar to John Grisham</li>
  <li>Chick lit (<em>Summer Sisters</em>, by Judy Blume) is similar to chick lit (<em>Bridget Jones</em>)</li>
  </ul>


  <p>Just for fun, let&#8217;s also look at books similar to <em>The Great Gatsby</em>:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/great-gatsby-correlation.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/great-gatsby-correlation.png" alt="Great Gatsby" /></a></p>

  <p>(Schoolboy memories, exactly.)</p>

  <h1>More Similarity Measures</h1>

  <p>Of course, there are lots of other similarity measures we could use besides correlation.</p>

  <h2>Cosine Similarity</h2>

  <p><a href="http://en.wikipedia.org/wiki/Cosine_similarity">Cosine similarity</a> is a another common vector-based similarity measure.</p>

  <figcaption><span>Cosine Similarity </span><a href="https://github.com/echen/scaldingale/blob/master/MovieSimilarities.scala">MovieSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">def</span> <span class="n">cosineSimilarity</span><span class="o">(</span><span class="n">dotProduct</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">ratingNorm</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">rating2Norm</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  </span><span class="line">  <span class="n">dotProduct</span> <span class="o">/</span> <span class="o">(</span><span class="n">ratingNorm</span> <span class="o">*</span> <span class="n">rating2Norm</span><span class="o">)</span>
  </span><span class="line"><span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <h2>Correlation, Take II</h2>

  <p>We can also also add a <em>regularized</em> correlation, by (say) adding N virtual movie pairs that have zero correlation. This helps avoid noise if some movie pairs have very few raters in common (for example, <em>The Great Gatsby</em> had an unlikely raw correlation of 1 with many other books, due simply to the fact that those book pairs had very few ratings).</p>

  <figcaption><span>Regularized Correlation </span><a href="https://github.com/echen/scaldingale/blob/master/MovieSimilarities.scala">MovieSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">def</span> <span class="n">regularizedCorrelation</span><span class="o">(</span><span class="n">size</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">dotProduct</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">ratingSum</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span>
  </span><span class="line">  <span class="n">rating2Sum</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">ratingNormSq</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">rating2NormSq</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span>
  </span><span class="line">  <span class="n">virtualCount</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">priorCorrelation</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  </span><span class="line">
  </span><span class="line">  <span class="k">val</span> <span class="n">unregularizedCorrelation</span> <span class="k">=</span> <span class="n">correlation</span><span class="o">(</span><span class="n">size</span><span class="o">,</span> <span class="n">dotProduct</span><span class="o">,</span> <span class="n">ratingSum</span><span class="o">,</span> <span class="n">rating2Sum</span><span class="o">,</span> <span class="n">ratingNormSq</span><span class="o">,</span> <span class="n">rating2NormSq</span><span class="o">)</span>
  </span><span class="line">  <span class="k">val</span> <span class="n">w</span> <span class="k">=</span> <span class="n">size</span> <span class="o">/</span> <span class="o">(</span><span class="n">size</span> <span class="o">+</span> <span class="n">virtualCount</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line">  <span class="n">w</span> <span class="o">*</span> <span class="n">unregularizedCorrelation</span> <span class="o">+</span> <span class="o">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">w</span><span class="o">)</span> <span class="o">*</span> <span class="n">priorCorrelation</span>
  </span><span class="line"><span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <h2>Jaccard Similarity</h2>

  <p>Recall that <a href="http://blog.echen.me/blog/2011/10/24/winning-the-netflix-prize-a-summary/">one of the lessons of the Netflix prize</a> was that implicit data can be quite useful &#8211; the mere fact that you rate a James Bond movie, even if you rate it quite horribly, suggests that you&#8217;d probably be interested in similar action films. So we can also ignore the value itself of each rating and use a <em>set</em>-based similarity measure like <a href="http://en.wikipedia.org/wiki/Jaccard_index">Jaccard similarity</a>.</p>

  <figcaption><span>Jaccard Similarity </span><a href="https://github.com/echen/scaldingale/blob/master/MovieSimilarities.scala">MovieSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">def</span> <span class="n">jaccardSimilarity</span><span class="o">(</span><span class="n">usersInCommon</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">totalUsers1</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">totalUsers2</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
  </span><span class="line">  <span class="k">val</span> <span class="n">union</span> <span class="k">=</span> <span class="n">totalUsers1</span> <span class="o">+</span> <span class="n">totalUsers2</span> <span class="o">-</span> <span class="n">usersInCommon</span>
  </span><span class="line">  <span class="n">usersInCommon</span> <span class="o">/</span> <span class="n">union</span>
  </span><span class="line"><span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <h2>Incorporation</h2>

  <p>Finally, let&#8217;s add all these similarity measures to our output.</p>

  <figcaption><span>Similarity Measures </span><a href="https://github.com/echen/scaldingale/blob/master/MovieSimilarities.scala">MovieSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  <span class="line-number">11</span>
  <span class="line-number">12</span>
  <span class="line-number">13</span>
  <span class="line-number">14</span>
  <span class="line-number">15</span>
  <span class="line-number">16</span>
  <span class="line-number">17</span>
  <span class="line-number">18</span>
  <span class="line-number">19</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">val</span> <span class="nc">PRIOR_COUNT</span> <span class="k">=</span> <span class="mi">10</span>
  </span><span class="line"><span class="k">val</span> <span class="nc">PRIOR_CORRELATION</span> <span class="k">=</span> <span class="mi">0</span>
  </span><span class="line">
  </span><span class="line"><span class="k">val</span> <span class="n">similarities</span> <span class="k">=</span>
  </span><span class="line">  <span class="n">vectorCalcs</span>
  </span><span class="line">    <span class="o">.</span><span class="n">map</span><span class="o">((</span><span class="-Symbol">&#39;size</span><span class="o">,</span> <span class="-Symbol">&#39;dotProduct</span><span class="o">,</span> <span class="-Symbol">&#39;ratingSum</span><span class="o">,</span> <span class="-Symbol">&#39;rating2Sum</span><span class="o">,</span> <span class="-Symbol">&#39;ratingNormSq</span><span class="o">,</span> <span class="-Symbol">&#39;rating2NormSq</span><span class="o">,</span> <span class="-Symbol">&#39;numRaters</span><span class="o">,</span> <span class="-Symbol">&#39;numRaters2</span><span class="o">)</span> <span class="o">-&gt;</span>
  </span><span class="line">      <span class="o">(</span><span class="-Symbol">&#39;correlation</span><span class="o">,</span> <span class="-Symbol">&#39;regularizedCorrelation</span><span class="o">,</span> <span class="-Symbol">&#39;cosineSimilarity</span><span class="o">,</span> <span class="-Symbol">&#39;jaccardSimilarity</span><span class="o">))</span> <span class="o">{</span>
  </span><span class="line">
  </span><span class="line">      <span class="n">fields</span> <span class="k">:</span> <span class="o">(</span><span class="kt">Double</span><span class="o">,</span> <span class="kt">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">)</span> <span class="k">=&gt;</span>
  </span><span class="line">
  </span><span class="line">      <span class="k">val</span> <span class="o">(</span><span class="n">size</span><span class="o">,</span> <span class="n">dotProduct</span><span class="o">,</span> <span class="n">ratingSum</span><span class="o">,</span> <span class="n">rating2Sum</span><span class="o">,</span> <span class="n">ratingNormSq</span><span class="o">,</span> <span class="n">rating2NormSq</span><span class="o">,</span> <span class="n">numRaters</span><span class="o">,</span> <span class="n">numRaters2</span><span class="o">)</span> <span class="k">=</span> <span class="n">fields</span>
  </span><span class="line">
  </span><span class="line">      <span class="k">val</span> <span class="n">corr</span> <span class="k">=</span> <span class="n">correlation</span><span class="o">(</span><span class="n">size</span><span class="o">,</span> <span class="n">dotProduct</span><span class="o">,</span> <span class="n">ratingSum</span><span class="o">,</span> <span class="n">rating2Sum</span><span class="o">,</span> <span class="n">ratingNormSq</span><span class="o">,</span> <span class="n">rating2NormSq</span><span class="o">)</span>
  </span><span class="line">      <span class="k">val</span> <span class="n">regCorr</span> <span class="k">=</span> <span class="n">regularizedCorrelation</span><span class="o">(</span><span class="n">size</span><span class="o">,</span> <span class="n">dotProduct</span><span class="o">,</span> <span class="n">ratingSum</span><span class="o">,</span> <span class="n">rating2Sum</span><span class="o">,</span> <span class="n">ratingNormSq</span><span class="o">,</span> <span class="n">rating2NormSq</span><span class="o">,</span> <span class="nc">PRIOR_COUNT</span><span class="o">,</span> <span class="nc">PRIOR_CORRELATION</span><span class="o">)</span>
  </span><span class="line">      <span class="k">val</span> <span class="n">cosSim</span> <span class="k">=</span> <span class="n">cosineSimilarity</span><span class="o">(</span><span class="n">dotProduct</span><span class="o">,</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">ratingNormSq</span><span class="o">),</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="o">(</span><span class="n">rating2NormSq</span><span class="o">))</span>
  </span><span class="line">      <span class="k">val</span> <span class="n">jaccard</span> <span class="k">=</span> <span class="n">jaccardSimilarity</span><span class="o">(</span><span class="n">size</span><span class="o">,</span> <span class="n">numRaters</span><span class="o">,</span> <span class="n">numRaters2</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line">      <span class="o">(</span><span class="n">corr</span><span class="o">,</span> <span class="n">regCorr</span><span class="o">,</span> <span class="n">cosSim</span><span class="o">,</span> <span class="n">jaccard</span><span class="o">)</span>
  </span><span class="line">    <span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <h1>Book Similarities Revisited</h1>

  <p>Let&#8217;s take another look at the book similarities above, now that we have these new fields.</p>

  <p>Here are some of the top Book-Crossing pairs, sorted by their shrunk correlation:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/top-book-crossing-sims.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/top-book-crossing-sims.png" alt="Top Book-Crossing Pairs" /></a></p>

  <p>Notice how regularization affects things: the <em>Dark Tower</em> pair has a pretty high raw correlation, but relatively few ratings (reducing our confidence in the raw correlation), so it ends up below the others.</p>

  <p>And here are books similar to <em>The Great Gatsby</em>, this time ordered by cosine similarity:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/great-gatsby.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/great-gatsby.png" alt="Great Gatsby" /></a></p>

  <h1>Input Abstraction</h1>

  <p>So our code right now is tied to our specific <code>ratings.tsv</code> input. But what if we change the way we store our ratings, or what if we want to generate similarities for something entirely different?</p>

  <p>Let&#8217;s abstract away our input. We&#8217;ll create a <a href="https://github.com/echen/scaldingale/blob/master/VectorSimilarities.scala">VectorSimilarities class</a> that represents input data in the following format:</p>

  <figcaption><span>Input abstraction </span><a href="https://github.com/echen/scaldingale/blob/master/VectorSimilarities.scala">VectorSimilarities.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="c1">// This is an abstract method that returns a Pipe (aka, a stream of rating tuples).</span>
  </span><span class="line"><span class="c1">// It takes in three symbols that name the user, item, and rating fields.</span>
  </span><span class="line"><span class="k">def</span> <span class="n">input</span><span class="o">(</span><span class="n">userField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">itemField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">ratingField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">)</span> <span class="k">:</span> <span class="kt">Pipe</span>
  </span><span class="line">
  </span><span class="line"><span class="k">val</span> <span class="n">ratings</span> <span class="k">=</span> <span class="n">input</span><span class="o">(</span><span class="-Symbol">&#39;user</span><span class="o">,</span> <span class="-Symbol">&#39;item</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">)</span>
  </span><span class="line"><span class="c1">// ...</span>
  </span><span class="line"><span class="c1">// The rest of the code remains essentially the same.</span>
  </span></code></pre></td></tr></table></div>


  <p>Whenever we want to define a new input format, we simply subclass <code>VectorSimilarities</code> and provide a concrete implementation of the <code>input</code> method.</p>

  <h2>Book-Crossings</h2>

  <p>For example, here&#8217;s a class I could have used to generate the book recommendations above:</p>

  <figcaption><span>BookCrossing similarities </span><a href="https://github.com/echen/scaldingale/blob/master/BookCrossing.scala">BookCrossing.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">class</span> <span class="nc">BookCrossing</span><span class="o">(</span><span class="n">args</span> <span class="k">:</span> <span class="kt">Args</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">VectorSimilarities</span><span class="o">(</span><span class="n">args</span><span class="o">)</span> <span class="o">{</span>
  </span><span class="line">  <span class="k">override</span> <span class="k">def</span> <span class="n">input</span><span class="o">(</span><span class="n">userField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">itemField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">ratingField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">)</span> <span class="k">:</span> <span class="kt">Pipe</span> <span class="o">=</span> <span class="o">{</span>
  </span><span class="line">    <span class="k">val</span> <span class="n">bookCrossingRatings</span> <span class="k">=</span>
  </span><span class="line">      <span class="nc">Tsv</span><span class="o">(</span><span class="s">&quot;book-crossing-ratings.tsv&quot;</span><span class="o">)</span>
  </span><span class="line">        <span class="o">.</span><span class="n">read</span>
  </span><span class="line">        <span class="o">.</span><span class="n">mapTo</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="n">userField</span><span class="o">,</span> <span class="n">itemField</span><span class="o">,</span> <span class="n">ratingField</span><span class="o">))</span> <span class="o">{</span> <span class="n">fields</span> <span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">String</span><span class="o">,</span> <span class="nc">Double</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">fields</span> <span class="o">}</span>
  </span><span class="line">
  </span><span class="line">    <span class="n">bookCrossingRatings</span>
  </span><span class="line">  <span class="o">}</span>
  </span><span class="line"><span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <p>The input method simply reads from a TSV file and lets the <code>VectorSimilarities</code> superclass do all the work. Instant recommendations, BOOM.</p>

  <h2>Song Similarities with Twitter + iTunes</h2>

  <p>But why limit ourselves to books? We do, after all, have Twitter at our fingertips&#8230;</p>

  <blockquote class="twitter-tweet"><p>rated Born This Way by Lady GaGa 5 stars <a href="http://t.co/wTYAwWqm" title="http://itun.es/iSg92N">itun.es/iSg92N</a> <a href="https://twitter.com/search/%2523iTunes">#iTunes</a></p>&mdash; gggf (@GalMusic92) <a href="https://twitter.com/GalMusic92/status/167267017865428996" data-datetime="2012-02-08T15:22:19+00:00">February 8, 2012</a></blockquote>


  <script src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


  <p>Since iTunes lets you send a tweet whenever you rate a song, we can use these to generate music recommendations!</p>

  <p>Again, we create a new class that overrides the abstract <code>input</code> defined in <code>VectorSimilarities</code>&#8230;</p>

  <figcaption><span>Song similarities with Twitter + iTunes </span><a href="https://github.com/echen/scaldingale/blob/master/ITunes.scala">ITunes.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  <span class="line-number">11</span>
  <span class="line-number">12</span>
  <span class="line-number">13</span>
  <span class="line-number">14</span>
  <span class="line-number">15</span>
  <span class="line-number">16</span>
  <span class="line-number">17</span>
  <span class="line-number">18</span>
  <span class="line-number">19</span>
  <span class="line-number">20</span>
  <span class="line-number">21</span>
  <span class="line-number">22</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">class</span> <span class="nc">ITunes</span><span class="o">(</span><span class="n">args</span> <span class="k">:</span> <span class="kt">Args</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">VectorSimilarities</span><span class="o">(</span><span class="n">args</span><span class="o">)</span> <span class="o">{</span>
  </span><span class="line">  <span class="c1">// Example tweet:</span>
  </span><span class="line">  <span class="c1">// rated New Kids On the Block: Super Hits by New Kids On the Block 5 stars http://itun.es/iSg3Fc #iTunes</span>
  </span><span class="line">  <span class="k">val</span> <span class="nc">ITUNES_REGEX</span> <span class="k">=</span> <span class="s">&quot;&quot;&quot;rated (.+?) by (.+?) (\d) stars .*? #iTunes&quot;&quot;&quot;</span><span class="o">.</span><span class="n">r</span>
  </span><span class="line">
  </span><span class="line">  <span class="k">override</span> <span class="k">def</span> <span class="n">input</span><span class="o">(</span><span class="n">userField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">itemField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">ratingField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">)</span> <span class="k">:</span> <span class="kt">Pipe</span> <span class="o">=</span> <span class="o">{</span>
  </span><span class="line">    <span class="k">val</span> <span class="n">itunesRatings</span> <span class="k">=</span>
  </span><span class="line">      <span class="c1">// This is a Twitter-internal tweet source, but you could just as easily scrape </span>
  </span><span class="line">      <span class="c1">// Twitter yourself and provide your own source of tweets: https://dev.twitter.com/docs</span>
  </span><span class="line">      <span class="nc">TweetSource</span><span class="o">()</span>
  </span><span class="line">        <span class="o">.</span><span class="n">mapTo</span><span class="o">(</span><span class="-Symbol">&#39;userId</span><span class="o">,</span> <span class="-Symbol">&#39;text</span><span class="o">)</span> <span class="o">{</span> <span class="n">s</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="n">getUserId</span><span class="o">,</span> <span class="n">s</span><span class="o">.</span><span class="n">getText</span><span class="o">)</span> <span class="o">}</span>
  </span><span class="line">        <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="-Symbol">&#39;text</span><span class="o">)</span> <span class="o">{</span> <span class="n">text</span> <span class="k">:</span> <span class="kt">String</span> <span class="o">=&gt;</span> <span class="n">text</span><span class="o">.</span><span class="n">contains</span><span class="o">(</span><span class="s">&quot;#iTunes&quot;</span><span class="o">)</span> <span class="o">}</span>
  </span><span class="line">        <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="-Symbol">&#39;text</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="-Symbol">&#39;song</span><span class="o">,</span> <span class="-Symbol">&#39;artist</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">))</span> <span class="o">{</span>
  </span><span class="line">          <span class="n">text</span> <span class="k">:</span> <span class="kt">String</span> <span class="o">=&gt;</span>
  </span><span class="line">          <span class="nc">ITUNES_REGEX</span><span class="o">.</span><span class="n">findFirstMatchIn</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span> <span class="n">_</span><span class="o">.</span><span class="n">subgroups</span> <span class="o">}.</span><span class="n">map</span> <span class="o">{</span> <span class="n">l</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">l</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">l</span><span class="o">(</span><span class="mi">1</span><span class="o">),</span> <span class="n">l</span><span class="o">(</span><span class="mi">2</span><span class="o">))</span> <span class="o">}</span>
  </span><span class="line">        <span class="o">}</span>
  </span><span class="line">        <span class="o">.</span><span class="n">rename</span><span class="o">((</span><span class="-Symbol">&#39;userId</span><span class="o">,</span> <span class="-Symbol">&#39;song</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="n">userField</span><span class="o">,</span> <span class="n">itemField</span><span class="o">,</span> <span class="n">ratingField</span><span class="o">))</span>
  </span><span class="line">        <span class="o">.</span><span class="n">project</span><span class="o">(</span><span class="n">userField</span><span class="o">,</span> <span class="n">itemField</span><span class="o">,</span> <span class="n">ratingField</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line">    <span class="n">itunesRatings</span>
  </span><span class="line">  <span class="o">}</span>
  </span><span class="line"><span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <p>&#8230;and snap! Here are some songs you might like if you recently listened to <strong>Beyoncé</strong>:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/beyonce.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/beyonce.png" alt="Jason Mraz" /></a></p>

  <p>And some recommended songs if you like <strong>Lady Gaga</strong>:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/lady-gaga.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/lady-gaga.png" alt="Lady Gaga" /></a></p>

  <p>GG Pandora.</p>

  <h2>Location Similarities with Foursquare Check-ins</h2>

  <p>But what if we don&#8217;t have explicit ratings? For example, we could be a news site that wants to generate article recommendations, and maybe we only have user <em>visits</em> on each story.</p>

  <p>Or what if we want to generate restaurant or tourist recommendations, when all we know is who visits each location?</p>

  <blockquote class="twitter-tweet"><p>I&#8217;m at Empire State Building (350 5th Ave., btwn 33rd & 34th St., New York) <a href="http://t.co/q6tXzf3n" title="http://4sq.com/zZ5xGd">4sq.com/zZ5xGd</a></p>&mdash; Simon Ackerman (@SimonAckerman) <a href="https://twitter.com/SimonAckerman/status/167232054247956481" data-datetime="2012-02-08T13:03:23+00:00">February 8, 2012</a></blockquote>


  <script src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


  <p>Let&#8217;s finally make Foursquare check-ins useful. (I kid, I kid.)</p>

  <p>Instead of using an explicit rating given to us, we can simply generate a dummy rating of 1 for each check-in. Correlation doesn&#8217;t make sense any more, but we can still pay attention to a measure like Jaccard simiilarity.</p>

  <p>So we simply create a new class that scrapes tweets for Foursquare check-in information&#8230;</p>

  <figcaption><span>Location similarities with Foursquare </span><a href="https://github.com/echen/scaldingale/blob/master/Foursquare.scala">Foursquare.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  <span class="line-number">11</span>
  <span class="line-number">12</span>
  <span class="line-number">13</span>
  <span class="line-number">14</span>
  <span class="line-number">15</span>
  <span class="line-number">16</span>
  <span class="line-number">17</span>
  <span class="line-number">18</span>
  <span class="line-number">19</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">class</span> <span class="nc">Foursquare</span><span class="o">(</span><span class="n">args</span> <span class="k">:</span> <span class="kt">Args</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">VectorSimilarities</span><span class="o">(</span><span class="n">args</span><span class="o">)</span> <span class="o">{</span>
  </span><span class="line">  <span class="c1">// Example tweet: I&#39;m at The Ambassador (673 Geary St, btw Leavenworth &amp; Jones, San Francisco) w/ 2 others http://4sq.com/xok3rI</span>
  </span><span class="line">  <span class="c1">// Let&#39;s limit to New York for simplicity.</span>
  </span><span class="line">  <span class="k">val</span> <span class="nc">FOURSQUARE_REGEX</span> <span class="k">=</span> <span class="s">&quot;&quot;&quot;I&#39;m at (.+?) \(.*? New York&quot;&quot;&quot;</span><span class="o">.</span><span class="n">r</span>
  </span><span class="line">
  </span><span class="line">  <span class="k">override</span> <span class="k">def</span> <span class="n">input</span><span class="o">(</span><span class="n">userField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">itemField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">ratingField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">)</span> <span class="k">:</span> <span class="kt">Pipe</span> <span class="o">=</span> <span class="o">{</span>
  </span><span class="line">    <span class="k">val</span> <span class="n">foursquareCheckins</span> <span class="k">=</span>
  </span><span class="line">      <span class="nc">TweetSource</span><span class="o">()</span>
  </span><span class="line">        <span class="o">.</span><span class="n">mapTo</span><span class="o">(</span><span class="-Symbol">&#39;userId</span><span class="o">,</span> <span class="-Symbol">&#39;text</span><span class="o">)</span> <span class="o">{</span> <span class="n">s</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="n">getUserId</span><span class="o">.</span><span class="n">toLong</span><span class="o">,</span> <span class="n">s</span><span class="o">.</span><span class="n">getText</span><span class="o">)</span> <span class="o">}</span>
  </span><span class="line">        <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="-Symbol">&#39;text</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="-Symbol">&#39;location</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">))</span> <span class="o">{</span>
  </span><span class="line">          <span class="n">text</span> <span class="k">:</span> <span class="kt">String</span> <span class="o">=&gt;</span>
  </span><span class="line">          <span class="nc">FOURSQUARE_REGEX</span><span class="o">.</span><span class="n">findFirstMatchIn</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span> <span class="n">_</span><span class="o">.</span><span class="n">subgroups</span> <span class="o">}.</span><span class="n">map</span> <span class="o">{</span> <span class="n">l</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">l</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span>
  </span><span class="line">        <span class="o">}</span>
  </span><span class="line">        <span class="o">.</span><span class="n">rename</span><span class="o">((</span><span class="-Symbol">&#39;userId</span><span class="o">,</span> <span class="-Symbol">&#39;location</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="n">userField</span><span class="o">,</span> <span class="n">itemField</span><span class="o">,</span> <span class="n">ratingField</span><span class="o">))</span>
  </span><span class="line">        <span class="o">.</span><span class="n">unique</span><span class="o">(</span><span class="n">userField</span><span class="o">,</span> <span class="n">itemField</span><span class="o">,</span> <span class="n">ratingField</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line">    <span class="n">foursquareCheckins</span>
  </span><span class="line">  <span class="o">}</span>
  </span><span class="line"><span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <p>&#8230;and bam! Here are locations similar to the <strong>Empire State Building</strong>:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/empire-state-building.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/empire-state-building.png" alt="Empire State Building" /></a></p>

  <p>Here are places you might want to check out, if you check-in at <strong>Bergdorf Goodman</strong>:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/bergdorf-goodman.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/bergdorf-goodman.png" alt="Bergdorf Goodman" /></a></p>

  <p>And here&#8217;s where to go after the <strong>Statue of Liberty</strong>:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/statue-of-liberty.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/statue-of-liberty.png" alt="Statue of Liberty" /></a></p>

  <p>Power of Twitter, yo.</p>

  <h1>RottenTomatoes Similarities</h1>

  <p>UPDATE: I found some movie data after all&#8230;</p>

  <blockquote class="twitter-tweet"><p>My review for &#8216;How to Train Your Dragon&#8217; on Rotten Tomatoes: 4 1/2 stars &gt;<a href="http://t.co/YTOKWLEt" title="http://bit.ly/xtw3d3">bit.ly/xtw3d3</a></p>&mdash; Benjamin West (@BenTheWest) <a href="https://twitter.com/BenTheWest/status/171772890121895936" data-datetime="2012-02-21T01:47:03+00:00">February 21, 2012</a></blockquote>


  <p>So let&#8217;s use RottenTomatoes tweets to recommend movies! Here&#8217;s the code for a class that searches for RottenTomatoes tweets:</p>

  <figcaption><span>Movie similarities with RottenTomatoes </span><a href="https://github.com/echen/scaldingale/blob/master/RottenTomatoes.scala">RottenTomatoes.scala</a></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  <span class="line-number">11</span>
  <span class="line-number">12</span>
  <span class="line-number">13</span>
  <span class="line-number">14</span>
  <span class="line-number">15</span>
  <span class="line-number">16</span>
  <span class="line-number">17</span>
  <span class="line-number">18</span>
  <span class="line-number">19</span>
  <span class="line-number">20</span>
  <span class="line-number">21</span>
  <span class="line-number">22</span>
  <span class="line-number">23</span>
  <span class="line-number">24</span>
  <span class="line-number">25</span>
  <span class="line-number">26</span>
  </pre></td><td class="code"><pre><code class="scala"><span class="line"><span class="k">class</span> <span class="nc">RottenTomatoes</span><span class="o">(</span><span class="n">args</span> <span class="k">:</span> <span class="kt">Args</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">VectorSimilarities</span><span class="o">(</span><span class="n">args</span><span class="o">)</span> <span class="o">{</span>
  </span><span class="line">  <span class="cm">/**</span>
  </span><span class="line"><span class="cm">   * Example tweets:</span>
  </span><span class="line"><span class="cm">   * My review for &#39;Hop&#39; on Rotten Tomatoes: 1 star &gt; http://bit.ly/AB7Tl4</span>
  </span><span class="line"><span class="cm">   * My review for &#39;The Bothersome Man (Den Brysomme mannen)&#39; on Rotten Tomatoes: 3 stars-A muddled Playtime in Paris,... http://tmto.es/AvPoO2</span>
  </span><span class="line"><span class="cm">   */</span>
  </span><span class="line">  <span class="k">val</span> <span class="nc">ROTTENTOMATOES_REGEX</span> <span class="k">=</span> <span class="s">&quot;&quot;&quot;My review for &#39;(.+?)&#39; on Rotten Tomatoes: (\d) star&quot;&quot;&quot;</span><span class="o">.</span><span class="n">r</span>
  </span><span class="line">
  </span><span class="line">  <span class="k">override</span> <span class="k">val</span> <span class="nc">MIN_NUM_RATERS</span> <span class="k">=</span> <span class="mi">2</span>
  </span><span class="line">  <span class="k">override</span> <span class="k">val</span> <span class="nc">MAX_NUM_RATERS</span> <span class="k">=</span> <span class="mi">1000</span>
  </span><span class="line">  <span class="k">override</span> <span class="k">val</span> <span class="nc">MIN_INTERSECTION</span> <span class="k">=</span> <span class="mi">2</span>
  </span><span class="line">
  </span><span class="line">  <span class="k">override</span> <span class="k">def</span> <span class="n">input</span><span class="o">(</span><span class="n">userField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">itemField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">,</span> <span class="n">ratingField</span> <span class="k">:</span> <span class="kt">Symbol</span><span class="o">)</span> <span class="k">:</span> <span class="kt">Pipe</span> <span class="o">=</span> <span class="o">{</span>
  </span><span class="line">    <span class="k">val</span> <span class="n">rottenTomatoesRatings</span> <span class="k">=</span>
  </span><span class="line">      <span class="nc">TweetSource</span><span class="o">()</span>
  </span><span class="line">        <span class="o">.</span><span class="n">mapTo</span><span class="o">(</span><span class="-Symbol">&#39;userId</span><span class="o">,</span> <span class="-Symbol">&#39;text</span><span class="o">)</span> <span class="o">{</span> <span class="n">s</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="n">getUserId</span><span class="o">.</span><span class="n">toLong</span><span class="o">,</span> <span class="n">s</span><span class="o">.</span><span class="n">getText</span><span class="o">)</span> <span class="o">}</span>
  </span><span class="line">        <span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="-Symbol">&#39;text</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="-Symbol">&#39;movie</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">))</span> <span class="o">{</span>
  </span><span class="line">          <span class="n">text</span> <span class="k">:</span> <span class="kt">String</span> <span class="o">=&gt;</span>
  </span><span class="line">          <span class="nc">ROTTENTOMATOES_REGEX</span><span class="o">.</span><span class="n">findFirstMatchIn</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="n">map</span> <span class="o">{</span> <span class="n">_</span><span class="o">.</span><span class="n">subgroups</span> <span class="o">}.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">x</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">toInt</span><span class="o">)</span> <span class="o">}</span>
  </span><span class="line">        <span class="o">}</span>
  </span><span class="line">        <span class="o">.</span><span class="n">rename</span><span class="o">((</span><span class="-Symbol">&#39;userId</span><span class="o">,</span> <span class="-Symbol">&#39;movie</span><span class="o">,</span> <span class="-Symbol">&#39;rating</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">(</span><span class="n">userField</span><span class="o">,</span> <span class="n">itemField</span><span class="o">,</span> <span class="n">ratingField</span><span class="o">))</span>
  </span><span class="line">        <span class="o">.</span><span class="n">unique</span><span class="o">(</span><span class="n">userField</span><span class="o">,</span> <span class="n">itemField</span><span class="o">,</span> <span class="n">ratingField</span><span class="o">)</span>
  </span><span class="line">
  </span><span class="line">    <span class="n">rottenTomatoesRatings</span>
  </span><span class="line">  <span class="o">}</span>
  </span><span class="line"><span class="o">}</span>
  </span></code></pre></td></tr></table></div>


  <p>And here are the most similar movies discovered:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/top-rottentomatoes-sims.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/top-rottentomatoes-sims.png" alt="Top RottenTomatoes Movies" /></a></p>

  <p>We see that</p>

  <ul>
  <li><em>Lord of the Rings</em>, <em>Harry Potter</em>, and <em>Star Wars</em> movies are similar to other <em>Lord of the Rings</em>, <em>Harry Potter</em>, and <em>Star Wars</em> movies</li>
  <li>Big science fiction blockbusters (<em>Avatar</em>) are similar to big science fiction blockbusters (<em>Inception</em>)</li>
  <li>People who like one Justin Timberlake movie (<em>Bad Teacher</em>) also like other Justin Timberlake Movies (<em>In Time</em>). Similarly with Michael Fassbender (<em>A Dangerous Method</em>, <em>Shame</em>)</li>
  <li>Art house movies (<em>The Tree of Life</em>) stick together (<em>Tinker Tailor Soldier Spy</em>)</li>
  </ul>


  <p>Let&#8217;s also look at the movies with the most <em>negative</em> correlation:</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/scaldingale/bottom-rottentomatoes-sims.png"><img src="http://dl.dropbox.com/u/10506/blog/scaldingale/bottom-rottentomatoes-sims.png" alt="Negative RottenTomatoes Movies" /></a></p>

  <p>(The more you like loud and dirty popcorn movies (<em>Thor</em>) and vamp romance (<em>Twilight</em>), the less you like arthouse? SGTM.)</p>

  <h1>Next Steps</h1>

  <p>Hopefully I gave you a taste of the awesomeness of Scalding. To learn even more:</p>

  <ul>
  <li>Check out <a href="https://github.com/twitter/scalding">Scalding on Github</a>.</li>
  <li>Read <a href="https://github.com/twitter/scalding/wiki/Getting-Started">this Getting Started Guide</a> on the Scalding wiki.</li>
  <li>Run through <a href="https://github.com/twitter/scalding/tree/master/tutorial">this code-based introduction</a>, complete with Scalding jobs that you can run in local mode.</li>
  <li>Browse <a href="https://github.com/twitter/scalding/wiki/API-Reference">the API reference</a>, which also contains many code snippets illustrating different Scalding functions (e.g., <code>map</code>, <code>filter</code>, <code>flatMap</code>, <code>groupBy</code>, <code>count</code>, <code>join</code>).</li>
  <li>And all the code for this post is <a href="https://github.com/echen/scaldingale">here</a>.</li>
  </ul>


  <p>Watch out for more documentation soon, and you should most definitely <a href="https://twitter.com/#!/scalding">follow @Scalding</a> on Twitter for updates or to ask any questions.</p>

  <h1>Mad Props</h1>

  <p>And finally, a huge shoutout to <a href="https://twitter.com/argyris">Argyris Zymnis</a>, <a href="https://twitter.com/avibryant">Avi Bryant</a>, and <a href="https://twitter.com/posco">Oscar Boykin</a>, the mastermind hackers who have spent (and continue spending!) unimaginable hours making Scalding a joy to use.</p>

  <p>@argyris, @avibryant, @posco: Thanks for it all. #awesomejobguys #loveit</p>
  </div>  
<script type= "text/javascript">
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
</script>

                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/2012/01/17/quick-introduction-to-ggplot2/">Quick Introduction to ggplot2</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/edwin-chen.html">Edwin Chen</a>
        </li>
        <li class="published" title="2012-01-17T04:15:00">
          on&nbsp;Tue 17 January 2012
        </li>

	</ul>

</div><!-- /.post-info -->
  <div class="entry-content"><p>This is a bare-bones introduction to <a href="http://had.co.nz/ggplot2/">ggplot2</a>, a visualization package in R. It assumes no knowledge of R.</p>

  <p>For a better-looking version of this post, see <a href="https://github.com/echen/ggplot2-tutorial">this Github repository</a>, which also contains some of the <a href="https://github.com/echen/ggplot2-tutorial/tree/master/data">example datasets</a> I use and a <a href="https://github.com/echen/ggplot2-tutorial/blob/master/ggplot2-tutorial.R">literate programming version</a> of this tutorial.</p>

  <h1>Preview</h1>

  <p>Let&#8217;s start with a preview of what ggplot2 can do.</p>

  <p>Given Fisher&#8217;s <a href="http://en.wikipedia.org/wiki/Iris_flower_data_set">iris</a> data set and one simple command&#8230;</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">,</span> color <span class="o">=</span> Species<span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p>&#8230;we can produce this plot of sepal length vs. petal length, colored by species.</p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-specied.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-specied.png" alt="Sepal vs. Petal, Colored by Species" /></a></p>

  <h1>Installation</h1>

  <p>You can download R <a href="http://cran.opensourceresources.org/">here</a>. After installation, you can launch R in interactive mode by either typing <code>R</code> on the command line or opening the standard GUI (which should have been included in the download).</p>

  <h1>R Basics</h1>

  <h2>Vectors</h2>

  <p>Vectors are a core data structure in R, and are created with <code>c()</code>. Elements in a vector must be of the same type.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">numbers <span class="o">=</span> c<span class="p">(</span><span class="m">23</span><span class="p">,</span> <span class="m">13</span><span class="p">,</span> <span class="m">5</span><span class="p">,</span> <span class="m">7</span><span class="p">,</span> <span class="m">31</span><span class="p">)</span>
  </span><span class="line">names <span class="o">=</span> c<span class="p">(</span><span class="s">&quot;edwin&quot;</span><span class="p">,</span> <span class="s">&quot;alice&quot;</span><span class="p">,</span> <span class="s">&quot;bob&quot;</span><span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p>Elements are indexed starting at 1, and are accessed with <code>[]</code> notation.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">numbers<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="c1"># 23</span>
  </span><span class="line">names<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="c1"># edwin</span>
  </span></code></pre></td></tr></table></div>


  <h2>Data frames</h2>

  <p><a href="http://www.r-tutor.com/r-introduction/data-frame">Data frames</a> are like matrices, but with named columns of different types (similar to <a href="http://code.google.com/p/sqldf/">database tables</a>).</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">books <span class="o">=</span> data.frame<span class="p">(</span>
  </span><span class="line">  title <span class="o">=</span> c<span class="p">(</span><span class="s">&quot;harry potter&quot;</span><span class="p">,</span> <span class="s">&quot;war and peace&quot;</span><span class="p">,</span> <span class="s">&quot;lord of the rings&quot;</span><span class="p">),</span> <span class="c1"># column named &quot;title&quot;</span>
  </span><span class="line">  author <span class="o">=</span> c<span class="p">(</span><span class="s">&quot;rowling&quot;</span><span class="p">,</span> <span class="s">&quot;tolstoy&quot;</span><span class="p">,</span> <span class="s">&quot;tolkien&quot;</span><span class="p">),</span>
  </span><span class="line">  num_pages <span class="o">=</span> c<span class="p">(</span><span class="s">&quot;350&quot;</span><span class="p">,</span> <span class="s">&quot;875&quot;</span><span class="p">,</span> <span class="s">&quot;500&quot;</span><span class="p">)</span>
  </span><span class="line"><span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p>You can access columns of a data frame with <code>$</code>.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">books<span class="p">$</span>title <span class="c1"># c(&quot;harry potter&quot;, &quot;war and peace&quot;, &quot;lord of the rings&quot;)</span>
  </span><span class="line">books<span class="p">$</span>author<span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="c1"># &quot;rowling&quot;</span>
  </span></code></pre></td></tr></table></div>


  <p>You can also create new columns with <code>$</code>.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">books<span class="p">$</span>num_bought_today <span class="o">=</span> c<span class="p">(</span><span class="m">10</span><span class="p">,</span> <span class="m">5</span><span class="p">,</span> <span class="m">8</span><span class="p">)</span>
  </span><span class="line">books<span class="p">$</span>num_bought_yesterday <span class="o">=</span> c<span class="p">(</span><span class="m">18</span><span class="p">,</span> <span class="m">13</span><span class="p">,</span> <span class="m">20</span><span class="p">)</span>
  </span><span class="line">  
  </span><span class="line">books<span class="p">$</span>total\_num\_bought <span class="o">=</span> books<span class="p">$</span>num_bought_today <span class="o">+</span> books<span class="p">$</span>num_bought_yesterday
  </span></code></pre></td></tr></table></div>


  <h2>read.table</h2>

  <p>Suppose you want to import a TSV file into R as a data frame.</p>

  <h3>tsv file without header</h3>

  <p>For example, consider the <a href="https://github.com/echen/r-tutorial/blob/master/data/students.tsv"><code>data/students.tsv</code></a> file (with columns describing each student&#8217;s age, test score, and name).</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line"><span class="m">13</span>   <span class="m">100</span> alice
  </span><span class="line"><span class="m">14</span>   <span class="m">95</span>  bob
  </span><span class="line"><span class="m">13</span>   <span class="m">82</span>  eve
  </span></code></pre></td></tr></table></div>


  <p>We can import this file into R using <a href="http://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html"><code>read.table()</code></a>.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">students <span class="o">=</span> read.table<span class="p">(</span><span class="s">&quot;data/students.tsv&quot;</span><span class="p">,</span>
  </span><span class="line">  header <span class="o">=</span> <span class="k-Variable">F</span><span class="p">,</span> <span class="c1"># file does not contain a header (`F` is short for `FALSE`), so we must manually specify column names                    </span>
  </span><span class="line">  sep <span class="o">=</span> <span class="s">&quot;\t&quot;</span><span class="p">,</span> <span class="c1"># file is tab-delimited        </span>
  </span><span class="line">  col.names <span class="o">=</span> c<span class="p">(</span><span class="s">&quot;age&quot;</span><span class="p">,</span> <span class="s">&quot;score&quot;</span><span class="p">,</span> <span class="s">&quot;name&quot;</span><span class="p">)</span> <span class="c1"># column names</span>
  </span><span class="line"><span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p>We can now access the different columns in the data frame with <code>students$age</code>, <code>students$score</code>, and <code>students$name</code>.</p>

  <h3>csv file with header</h3>

  <p>For an example of a file in a different format, look at the <a href="https://github.com/echen/r-tutorial/blob/master/data/studentsWithHeader.tsv"><code>data/studentsWithHeader.tsv</code></a> file.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">age<span class="p">,</span>score<span class="p">,</span>name
  </span><span class="line"><span class="m">13</span><span class="p">,</span><span class="m">100</span><span class="p">,</span>alice
  </span><span class="line"><span class="m">14</span><span class="p">,</span><span class="m">95</span><span class="p">,</span>bob
  </span><span class="line"><span class="m">13</span><span class="p">,</span><span class="m">82</span><span class="p">,</span>eve
  </span></code></pre></td></tr></table></div>


  <p>Here we have the same data, but now the file is comma-delimited and contains a header. We can import this file with</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">students <span class="o">=</span> read.table<span class="p">(</span><span class="s">&quot;data/students.tsv&quot;</span><span class="p">,</span>
  </span><span class="line">  sep <span class="o">=</span> <span class="s">&quot;,&quot;</span><span class="p">,</span>
  </span><span class="line">  header <span class="o">=</span> <span class="k-Variable">T</span>  <span class="c1"># first line contains column names, so we can immediately call `students$age`        </span>
  </span><span class="line"><span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p>(Note: there is also a <code>read.csv</code> function that uses <code>sep = ","</code> by default.)</p>

  <h2>help</h2>

  <p>There are many more options that <code>read.table</code> can take. For a list of these, just type <code>help(read.table)</code> (or <code>?read.table</code>) at the prompt to access documentation.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line"><span class="c1"># These work for other functions as well.</span>
  </span><span class="line">help<span class="p">(</span>read.table<span class="p">)</span>
  </span><span class="line">?read.table
  </span></code></pre></td></tr></table></div>


  <h1>ggplot2</h1>

  <p>With these R basics in place, let&#8217;s dive into the ggplot2 package.</p>

  <h2>Installation</h2>

  <p>One of R&#8217;s greatest strengths is its excellent set of <a href="http://cran.r-project.org/web/packages/available_packages_by_name.html">packages</a>. To install a package, you can use the <code>install.packages()</code> function.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">install.packages<span class="p">(</span><span class="s">&quot;ggplot2&quot;</span><span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p>To load a package into your current R session, use <code>library()</code>.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">library<span class="p">(</span>ggplot2<span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <h2>Scatterplots with qplot()</h2>

  <p>Let&#8217;s look at how to create a scatterplot in ggplot2. We&#8217;ll use the <code>iris</code> data frame that&#8217;s automatically loaded into R.</p>

  <p>What does the data frame contain? We can use the <code>head</code> function to look at the first few rows.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  <span class="line-number">10</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">head<span class="p">(</span>iris<span class="p">)</span> <span class="c1"># by default, head displays the first 6 rows. see `?head`</span>
  </span><span class="line">head<span class="p">(</span>iris<span class="p">,</span> n <span class="o">=</span> <span class="m">10</span><span class="p">)</span> <span class="c1"># we can also explicitly set the number of rows to display</span>
  </span><span class="line">
  </span><span class="line">Sepal.Length Sepal.Width Petal.Length Petal.Width Species
  </span><span class="line">         <span class="m">5.1</span>         <span class="m">3.5</span>          <span class="m">1.4</span>         <span class="m">0.2</span>  setosa
  </span><span class="line">         <span class="m">4.9</span>         <span class="m">3.0</span>          <span class="m">1.4</span>         <span class="m">0.2</span>  setosa
  </span><span class="line">         <span class="m">4.7</span>         <span class="m">3.2</span>          <span class="m">1.3</span>         <span class="m">0.2</span>  setosa
  </span><span class="line">         <span class="m">4.6</span>         <span class="m">3.1</span>          <span class="m">1.5</span>         <span class="m">0.2</span>  setosa
  </span><span class="line">         <span class="m">5.0</span>         <span class="m">3.6</span>          <span class="m">1.4</span>         <span class="m">0.2</span>  setosa
  </span><span class="line">         <span class="m">5.4</span>         <span class="m">3.9</span>          <span class="m">1.7</span>         <span class="m">0.4</span>  setosa
  </span></code></pre></td></tr></table></div>


  <p>(The data frame actually contains three types of species: setosa, versicolor, and virginica.)</p>

  <p>Let&#8217;s plot <code>Sepal.Length</code> against <code>Petal.Length</code> using ggplot2&#8217;s <code>qplot()</code> function.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">)</span>
  </span><span class="line"><span class="c1"># Plot Sepal.Length vs. Petal.Length, using data from the `iris` data frame.</span>
  </span><span class="line"><span class="c1"># * First argument `Sepal.Length` goes on the x-axis.</span>
  </span><span class="line"><span class="c1"># * Second argument `Petal.Length` goes on the y-axis.</span>
  </span><span class="line"><span class="c1"># * `data = iris` means to look for this data in the `iris` data frame.    </span>
  </span></code></pre></td></tr></table></div>


  <p></p>

  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal.png" alt="Sepal Length vs. Petal Length" /></a></p>

  <p>To see where each species is located in this graph, we can color each point by adding a <code>color = Species</code> argument.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">,</span> color <span class="o">=</span> Species<span class="p">)</span> <span class="c1"># dude!</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-specied.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-specied.png" alt="Sepal vs. Petal, Colored by Species" /></a></p>

  <p>Similarly, we can let the size of each point denote sepal width, by adding a <code>size = Sepal.Width</code> argument.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">,</span> color <span class="o">=</span> Species<span class="p">,</span> size <span class="o">=</span> Petal.Width<span class="p">)</span>
  </span><span class="line"><span class="c1"># We see that Iris setosa flowers have the narrowest petals.</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-sized.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-sized.png" alt="Sepal vs. Petal, Sized by Petal Width" /></a></p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">,</span> color <span class="o">=</span> Species<span class="p">,</span> size <span class="o">=</span> Petal.Width<span class="p">,</span> alpha <span class="o">=</span> I<span class="p">(</span><span class="m">0.7</span><span class="p">))</span>
  </span><span class="line"><span class="c1"># By setting the alpha of each point to 0.7, we reduce the effects of overplotting.</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-alpha.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-alpha.png" alt="Sepal vs. Petal, with Transparency" /></a></p>

  <p>Finally, let&#8217;s fix the axis labels and add a title to the plot.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">,</span> color <span class="o">=</span> Species<span class="p">,</span>
  </span><span class="line">  xlab <span class="o">=</span> <span class="s">&quot;Sepal Length&quot;</span><span class="p">,</span> ylab <span class="o">=</span> <span class="s">&quot;Petal Length&quot;</span><span class="p">,</span>
  </span><span class="line">  main <span class="o">=</span> <span class="s">&quot;Sepal vs. Petal Length in Fisher&#39;s Iris data&quot;</span><span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-titled.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-titled.png" alt="Sepal vs. Petal, Titled" /></a></p>

  <h2>Other common geoms</h2>

  <p>In the scatterplot examples above, we implicitly used a <em>point</em> <strong>geom</strong>, the default when you supply two arguments to <code>qplot()</code>.</p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line"><span class="c1"># These two invocations are equivalent.</span>
  </span><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">,</span> geom <span class="o">=</span> <span class="s">&quot;point&quot;</span><span class="p">)</span>
  </span><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p>But we can also easily use other types of geoms to create more kinds of plots.</p>

  <h3>Barcharts: geom = &#8220;bar&#8221;</h3>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  <span class="line-number">5</span>
  <span class="line-number">6</span>
  <span class="line-number">7</span>
  <span class="line-number">8</span>
  <span class="line-number">9</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">movies <span class="o">=</span> data.frame<span class="p">(</span>
  </span><span class="line">  director <span class="o">=</span> c<span class="p">(</span><span class="s">&quot;spielberg&quot;</span><span class="p">,</span> <span class="s">&quot;spielberg&quot;</span><span class="p">,</span> <span class="s">&quot;spielberg&quot;</span><span class="p">,</span> <span class="s">&quot;jackson&quot;</span><span class="p">,</span> <span class="s">&quot;jackson&quot;</span><span class="p">),</span>
  </span><span class="line">  movie <span class="o">=</span> c<span class="p">(</span><span class="s">&quot;jaws&quot;</span><span class="p">,</span> <span class="s">&quot;avatar&quot;</span><span class="p">,</span> <span class="s">&quot;schindler&#39;s list&quot;</span><span class="p">,</span> <span class="s">&quot;lotr&quot;</span><span class="p">,</span> <span class="s">&quot;king kong&quot;</span><span class="p">),</span>
  </span><span class="line">  minutes <span class="o">=</span> c<span class="p">(</span><span class="m">124</span><span class="p">,</span> <span class="m">163</span><span class="p">,</span> <span class="m">195</span><span class="p">,</span> <span class="m">600</span><span class="p">,</span> <span class="m">187</span><span class="p">)</span>
  </span><span class="line"><span class="p">)</span>
  </span><span class="line">
  </span><span class="line"><span class="c1"># Plot the number of movies each director has.</span>
  </span><span class="line">qplot<span class="p">(</span>director<span class="p">,</span> data <span class="o">=</span> movies<span class="p">,</span> geom <span class="o">=</span> <span class="s">&quot;bar&quot;</span><span class="p">,</span> ylab <span class="o">=</span> <span class="s">&quot;# movies&quot;</span><span class="p">)</span>
  </span><span class="line"><span class="c1"># By default, the height of each bar is simply a count.</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/num-movies.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/num-movies.png" alt="# Movies" /></a></p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line"><span class="c1"># But we can also supply a different weight.</span>
  </span><span class="line"><span class="c1"># Here the height of each bar is the total running time of the director&#39;s movies.</span>
  </span><span class="line">qplot<span class="p">(</span>director<span class="p">,</span> weight <span class="o">=</span> minutes<span class="p">,</span> data <span class="o">=</span> movies<span class="p">,</span> geom <span class="o">=</span> <span class="s">&quot;bar&quot;</span><span class="p">,</span> ylab <span class="o">=</span> <span class="s">&quot;total length (min.)&quot;</span><span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/total-length.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/total-length.png" alt="Total Running Time" /></a></p>

  <h3>Line charts: geom = &#8220;line&#8221;</h3>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line">qplot<span class="p">(</span>Sepal.Length<span class="p">,</span> Petal.Length<span class="p">,</span> data <span class="o">=</span> iris<span class="p">,</span> geom <span class="o">=</span> <span class="s">&quot;line&quot;</span><span class="p">,</span> color <span class="o">=</span> Species<span class="p">)</span>
  </span><span class="line"><span class="c1"># Using a line geom doesn&#39;t really make sense here, but hey.</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-lined.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/sepal-vs-petal-lined.png" alt="Sepal vs. Petal, Lined" /></a></p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  <span class="line-number">3</span>
  <span class="line-number">4</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line"><span class="c1"># `Orange` is another built-in data frame that describes the growth of orange trees.</span>
  </span><span class="line">qplot<span class="p">(</span>age<span class="p">,</span> circumference<span class="p">,</span> data <span class="o">=</span> Orange<span class="p">,</span> geom <span class="o">=</span> <span class="s">&quot;line&quot;</span><span class="p">,</span>
  </span><span class="line">  colour <span class="o">=</span> Tree<span class="p">,</span>
  </span><span class="line">  main <span class="o">=</span> <span class="s">&quot;How does orange tree circumference vary with age?&quot;</span><span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/orange-tree-growth.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/orange-tree-growth.png" alt="Orange Tree Growth" /></a></p>

  <figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
  <span class="line-number">2</span>
  </pre></td><td class="code"><pre><code class="r"><span class="line"><span class="c1"># We can also plot both points and lines.</span>
  </span><span class="line">qplot<span class="p">(</span>age<span class="p">,</span> circumference<span class="p">,</span> data <span class="o">=</span> Orange<span class="p">,</span> geom <span class="o">=</span> c<span class="p">(</span><span class="s">&quot;point&quot;</span><span class="p">,</span> <span class="s">&quot;line&quot;</span><span class="p">),</span> colour <span class="o">=</span> Tree<span class="p">)</span>
  </span></code></pre></td></tr></table></div>


  <p><a href="http://dl.dropbox.com/u/10506/blog/r/ggplot2/orange-tree-pointed.png"><img src="http://dl.dropbox.com/u/10506/blog/r/ggplot2/orange-tree-pointed.png" alt="Orange Tree with Points" /></a></p>

  <p>And that&#8217;s it with what I&#8217;ll cover.</p>

  <h1>Next Steps</h1>

  <p>I skipped over a lot of aspects of R and ggplot2 in this intro.</p>

  <p>For example,</p>

  <ul>
  <li>There are many geoms (and other functionalities) in ggplot2 that I didn&#8217;t cover, e.g., <a href="http://had.co.nz/ggplot2/geom_boxplot.html">boxplots</a> and <a href="http://had.co.nz/ggplot2/geom_histogram.html">histograms</a>.</li>
  <li>I didn&#8217;t talk about ggplot2&#8217;s layering system, or the <a href="http://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448">grammar of graphics</a> it&#8217;s based on.</li>
  </ul>


  <p>So I&#8217;ll end with some additional resources on R and ggplot2.</p>

  <ul>
  <li>I don&#8217;t use it myself, but <a href="http://rstudio.org/">RStudio</a> is a popular IDE for R.</li>
  <li>The <a href="http://had.co.nz/ggplot2/">official ggplot2 documentation</a> is great and has lots of examples. There&#8217;s also an excellent <a href="http://www.amazon.com/ggplot2-Elegant-Graphics-Data-Analysis/dp/0387981403">book</a>.</li>
  <li><a href="http://plyr.had.co.nz/">plyr</a> is another fantastic R package that&#8217;s also by Hadley Wickham (the author of ggplot2).</li>
  <li>The <a href="http://cran.r-project.org/doc/manuals/R-intro.html">official R introduction</a> is okay, but definitely not great. I haven&#8217;t found any R tutorials I really like, but I&#8217;ve heard good things about <a href="http://www.amazon.com/Art-Programming-Statistical-Software-Design/dp/1593273843">The Art of R Programming</a>.</li>
  </ul>

  </div>  
<script type= "text/javascript">
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
</script>

                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/2012/01/03/introduction-to-conditional-random-fields/">Introduction to Conditional Random Fields</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/edwin-chen.html">Edwin Chen</a>
        </li>
        <li class="published" title="2012-01-03T04:15:00">
          on&nbsp;Tue 03 January 2012
        </li>

	</ul>

</div><!-- /.post-info -->
  <div class="entry-content"><p>Imagine you have a sequence of snapshots from a day in Justin Bieber&#8217;s life, and you want to label each image with the activity it represents (eating, sleeping, driving, etc.). How can you do this?</p>

  <p>One way is to ignore the sequential nature of the snapshots, and build a <em>per-image</em> classifier. For example, given a month&#8217;s worth of labeled snapshots, you might learn that dark images taken at 6am tend to be about sleeping, images with lots of bright colors tend to be about dancing, images of cars are about driving, and so on.</p>

  <p>By ignoring this sequential aspect, however, you lose a lot of information. For example, what happens if you see a close-up picture of a mouth &#8211; is it about singing or eating? If you know that the <em>previous</em> image is a picture of Justin Bieber eating or cooking, then it&#8217;s more likely this picture is about eating; if, however, the previous image contains Justin Bieber singing or dancing, then this one probably shows him singing as well.</p>

  <p>Thus, to increase the accuracy of our labeler, we should incorporate the labels of nearby photos, and this is precisely what a <strong>conditional random field</strong> does.</p>

  <h1>Part-of-Speech Tagging</h1>

  <p>Let&#8217;s go into some more detail, using the more common example of <strong>part-of-speech tagging</strong>.</p>

  <p>In POS tagging, the goal is to label a sentence (a sequence of words or tokens) with tags like ADJECTIVE, NOUN, PREPOSITION, VERB, ADVERB, ARTICLE.</p>

  <p>For example, given the sentence &#8220;Bob drank coffee at Starbucks&#8221;, the labeling might be &#8220;Bob (NOUN) drank (VERB) coffee (NOUN) at (PREPOSITION) Starbucks (NOUN)&#8221;.</p>

  <p>So let&#8217;s build a conditional random field to label sentences with their parts of speech. Just like any classifier, we&#8217;ll first need to decide on a set of feature functions $f_i$.</p>

  <h2>Feature Functions in a CRF</h2>

  <p>In a CRF, each <strong>feature function</strong> is a function that takes in as input:</p>

  <ul>
  <li>a sentence s</li>
  <li>the position i of a word in the sentence</li>
  <li>the label $l_i$ of the current word</li>
  <li>the label $l_{i-1}$ of the previous word</li>
  </ul>


  <p>and outputs a real-valued number (though the numbers are often just either 0 or 1).</p>

  <p>(Note: by restricting our features to depend on only the <em>current</em> and <em>previous</em> labels, rather than arbitrary labels throughout the sentence, I&#8217;m actually building the special case of a <strong>linear-chain CRF</strong>. For simplicity, I&#8217;m going to ignore general CRFs in this post.)</p>

  <p>For example, one possible feature function could measure how much we suspect that the current word should be labeled as an adjective given that the previous word is &#8220;very&#8221;.</p>

  <h2>Features to Probabilities</h2>

  <p>Next, assign each feature function $f_j$ a <strong>weight</strong> $\lambda_j$ (I&#8217;ll talk below about how to learn these weights from the data). Given a sentence s, we can now score a labeling l of s by adding up the weighted features over all words in the sentence:</p>

  <p>$score(l | s) = \sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})$</p>

  <p>(The first sum runs over each feature function $j$, and the inner sum runs over each position $i$ of the sentence.)</p>

  <p>Finally, we can transform these scores into probabilities $p(l | s)$ between 0 and 1 by exponentiating and normalizing:</p>

  <p>$p(l | s) = \frac{exp[score(l|s)]}{\sum_{l&#8217;} exp[score(l&#8217;|s)]} = \frac{exp[\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l_i, l_{i-1})]}{\sum_{l&#8217;} exp[\sum_{j = 1}^m \sum_{i = 1}^n \lambda_j f_j(s, i, l&#8217;_i, l&#8217;_{i-1})]}$</p>

  <h2>Example Feature Functions</h2>

  <p>So what do these feature functions look like? Examples of POS tagging features could include:</p>

  <ul>
  <li>$f_1(s, i, l_i, l_{i-1}) = 1$ if $l_i =$ ADVERB and the ith word ends in &#8220;-ly&#8221;; 0 otherwise.

  <ul>
  <li>If the weight $\lambda_1$ associated with this feature is large and positive, then this feature is essentially saying that we prefer labelings where words ending in -ly get labeled as ADVERB.</li>
  </ul>
  </li>
  <li>$f_2(s, i, l_i, l_{i-1}) = 1$ if $i = 1$, $l_i =$ VERB, and the sentence ends in a question mark; 0 otherwise.

  <ul>
  <li>Again, if the weight $\lambda_2$ associated with this feature is large and positive, then labelings that assign VERB to the first word in a question (e.g., &#8220;Is this a sentence beginning with a verb?&#8221;) are preferred.</li>
  </ul>
  </li>
  <li>$f_3(s, i, l_i, l_{i-1}) = 1$ if $l_{i-1} =$ ADJECTIVE and $l_i =$ NOUN; 0 otherwise.

  <ul>
  <li>Again, a positive weight for this feature means that adjectives tend to be followed by nouns.</li>
  </ul>
  </li>
  <li>$f_4(s, i, l_i, l_{i-1}) = 1$ if $l_{i-1} =$ PREPOSITION and $l_i =$ PREPOSITION.

  <ul>
  <li>A <em>negative</em> weight $\lambda_4$ for this function would mean that prepositions don&#8217;t tend to follow prepositions, so we should avoid labelings where this happens.</li>
  </ul>
  </li>
  </ul>


  <p>And that&#8217;s it! To sum up: to build a conditional random field, you just define a bunch of feature functions (which can depend on the entire sentence, a current position, and nearby labels), assign them weights, and add them all together, transforming at the end to a probability if necessary.</p>

  <p>Now let&#8217;s step back and compare CRFs to some other common machine learning techniques.</p>

  <h1>Smells like Logistic Regression&#8230;</h1>

  <p>The form of the CRF probabilities
  $p(l | s) = \frac{exp[\sum_{j = 1}^m \sum_{i = 1}^n f_j(s, i, l_i, l_{i-1})]}{\sum_{l&#8217;} exp[\sum_{j = 1}^m \sum_{i = 1}^n f_j(s, i, l&#8217;_i, l&#8217;_{i-1})]}$
  might look <a href="http://en.wikipedia.org/wiki/Logistic_regression">familiar</a>.</p>

  <p>That&#8217;s because CRFs are indeed basically the sequential version of <strong>logistic regression</strong>: whereas logistic regression is a log-linear model for <em>classification</em>, CRFs are a log-linear model for <em>sequential labels</em>.</p>

  <h1>Looks like HMMs&#8230;</h1>

  <p>Recall that <strong><a href="http://en.wikipedia.org/wiki/Hidden_Markov_model">Hidden Markov Models</a></strong> are another model for part-of-speech tagging (and sequential labeling in general). Whereas CRFs throw any bunch of functions together to get a label score, HMMs take a <em>generative</em> approach to labeling, defining</p>

  <p>$p(l,s) = p(l_1) \prod_i p(l_i | l_{i-1}) p(w_i | l_i)$</p>

  <p>where</p>

  <ul>
  <li>$p(l_i | l_{i-1})$ are <strong>transition</strong> probabilities (e.g., the probability that a preposition is followed by a noun);</li>
  <li>$p(w_i | l_i)$ are <strong>emission</strong> probabilities (e.g., the probability that a noun emits the word &#8220;dad&#8221;).</li>
  </ul>


  <p>So how do HMMs compare to CRFs? CRFs are more powerful &#8211; they can model everything HMMs can and more. One way of seeing this is as follows.</p>

  <p>Note that the log of the HMM probability is $\log p(l,s) = \log p(l_0) + \sum_i \log p(l_i | l_{i-1}) + \sum_i \log p(w_i | l_i)$. This has exactly the log-linear form of a CRF if we consider these log-probabilities to be the weights associated to binary transition and emission indicator features.</p>

  <p>That is, we can build a CRF equivalent to any HMM by&#8230;</p>

  <ul>
  <li>For each HMM <em>transition</em> probability $ p(l_i = y | l_{i-1} = x) $, define a set of CRF transition features of the form $f_{x,y}(s, i, l_i, l_{i-1}) = 1$ if $l_i = y$ and $l_{i-1} = x$. Give each feature a weight of $w_{x,y} = \log p(l_i = y | l_{i-1} = x)$.</li>
  <li>Similarly, for each HMM <em>emission</em> probability $p(w_i = z | l_{i} = x)$, define a set of CRF emission features of the form $g_{x,y}(s, i, l_i, l_{i-1}) = 1$ if $w_i = z$ and $l_i = x$. Give each feature a weight of $w_{x,z} = \log p(w_i = z | l_i = x)$.</li>
  </ul>


  <p>Thus, the score $p(l|s)$ computed by a CRF using these feature functions is precisely proportional to the score computed by the associated HMM, and so every HMM is equivalent to some CRF.</p>

  <p>However, CRFs can model a much richer set of label distributions as well, for two main reasons:</p>

  <ul>
  <li><strong>CRFs can define a much larger set of features.</strong> Whereas HMMs are necessarily <em>local</em> in nature (because they&#8217;re constrained to binary transition and emission feature functions, which force each word to depend only on the current label and each label to depend only on the previous label), CRFs can use more <em>global</em> features. For example, one of the features in our POS tagger above increased the probability of labelings that tagged the <em>first</em> word of a sentence as a VERB if the <em>end</em> of the sentence contained a question mark.</li>
  <li><strong>CRFs can have arbitrary weights.</strong> Whereas the probabilities of an HMM must satisfy certain constraints (e.g., $0 &lt;= p(w_i | l_i) &lt;= 1, \sum_w p(w_i = w | l_1) = 1)$, the weights of a CRF are unrestricted (e.g., $\log p(w_i | l_i)$ can be anything it wants).</li>
  </ul>


  <h1>Learning Weights</h1>

  <p>Let&#8217;s go back to the question of how to learn the feature weights in a CRF. One way is (surprise) to use <strong>gradient ascent</strong>.</p>

  <p>Assume we have a bunch of training examples (sentences and associated part-of-speech labels). Randomly initialize the weights of our CRF model.
  To shift these randomly initialized weights to the correct ones, for each training example&#8230;</p>

  <ul>
  <li>Go through each feature function $f_i$, and calculate the gradient of the log probability of the training example with respect to $\lambda_i$: $\frac{\partial}{\partial w_j} \log p(l | s) = \sum_{j = 1}^m f_i(s, j, l_j, l_{j-1}) - \sum_{l&#8217;} p(l&#8217; | s) \sum_{j = 1}^m f_i(s, j, l&#8217;_j, l&#8217;_{j-1})$</li>
  <li>Note that the first term in the gradient is the contribution of feature $f_i$ under the <em>true</em> label, and the second term in the gradient is the <em>expected</em> contribution of feature $f_i$ under the current model. This is exactly the form you&#8217;d expect gradient ascent to take.</li>
  <li>Move $\lambda_i$ in the direction of the gradient: $\lambda_i = \lambda_i + \alpha [\sum_{j = 1}^m f_i(s, j, l_j, l_{j-1}) - \sum_{l&#8217;} p(l&#8217; | s) \sum_{j = 1}^m f_i(s, j, l&#8217;_j, l&#8217;_{j-1})]$ where $\alpha$ is some learning rate.</li>
  <li>Repeat the previous steps until some stopping condition is reached (e.g., the updates fall below some threshold).</li>
  </ul>


  <p>In other words, every step takes the difference between what we want the model to learn and the model&#8217;s current state, and moves $\lambda_i$ in the direction of this difference.</p>

  <h1>Finding the Optimal Labeling</h1>

  <p>Suppose we&#8217;ve trained our CRF model, and now a new sentence comes in. How do we do label it?</p>

  <p>The naive way is to calculate $p(l | s)$ for every possible labeling l, and then choose the label that maximizes this probability. However, since there are $k^m$ possible labels for a tag set of size k and a sentence of length m, this approach would have to check an exponential number of labels.</p>

  <p>A better way is to realize that (linear-chain) CRFs satisfy an <a href="http://en.wikipedia.org/wiki/Optimal_substructure">optimal substructure</a> property that allows us to use a (polynomial-time) dynamic programming algorithm to find the optimal label, similar to the <a href="http://en.wikipedia.org/wiki/Viterbi_algorithm">Viterbi algorithm</a> for HMMs.</p>

  <h1>A More Interesting Application</h1>

  <p>Okay, so part-of-speech tagging is kind of boring, and there are plenty of existing POS taggers out there. When might you use a CRF in real life?</p>

  <p>Suppose you want to mine Twitter for the types of presents people received for Christmas:</p>

  <blockquote class="twitter-tweet"><p>What people on Twitter wanted for Christmas, and what they got: <a href="http://t.co/EGeKTBgF" title="http://twitter.com/edchedch/status/153683967315419136/photo/1">twitter.com/edchedch/statu…</a></p>— Edwin Chen (@edchedch) <a href="https://twitter.com/edchedch/status/153683967315419136" data-datetime="2012-01-02T03:48:10+00:00">January 2, 2012</a></blockquote>


  <script src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


  <p>(Yes, I just embedded a tweet. BOOM.)</p>

  <p>How can you figure out which words refer to gifts?</p>

  <p>To gather data for the graphs above, I simply looked for phrases of the form &#8220;I want XXX for Christmas&#8221; and &#8220;I got XXX for Christmas&#8221;. However, a more sophisticated CRF variant could use a GIFT part-of-speech-like tag (even adding other tags like GIFT-GIVER and GIFT-RECEIVER, to get even more information on who got what from whom) and treat this like a POS tagging problem. Features could be based around things like &#8220;this word is a GIFT if the previous word was a GIFT-RECEIVER and the word before that was &#8216;gave&#8217;&#8221; or &#8220;this word is a GIFT if the next two words are &#8216;for Christmas&#8217;&#8221;.</p>

  <h1>Fin</h1>

  <p>I&#8217;ll end with some more random thoughts:</p>

  <ul>
  <li>I explicitly skipped over the graphical models framework that conditional random fields sit in, because I don&#8217;t think they add much to an initial understanding of CRFs. But if you&#8217;re interested in learning more, Daphne Koller is teaching a free, online course on <a href="http://www.pgm-class.org/">graphical models</a> starting in January.</li>
  <li>Or, if you&#8217;re more interested in the many NLP applications of CRFs (like part-of-speech tagging or <a href="http://en.wikipedia.org/wiki/Named-entity_recognition">named entity extraction</a>), Manning and Jurafsky are teaching an <a href="http://www.nlp-class.org/">NLP class</a> in the same spirit.</li>
  <li>I also glossed a bit over the analogy between CRFs:HMMs and Logistic Regression:Naive Bayes. This image (from <a href="http://arxiv.org/pdf/1011.4088v1">Sutton and McCallum&#8217;s introduction to conditional random fields</a>) sums it up, and shows the graphical model nature of CRFs as well:</li>
  </ul>


  <p><a href="http://dl.dropbox.com/u/10506/blog/crfs/crf-diagram.png"><img src="http://dl.dropbox.com/u/10506/blog/crfs/crf-diagram.png" alt="CRF Diagram" /></a></p></div>
  
<script type= "text/javascript">
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
</script>

                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/2011/10/24/winning-the-netflix-prize-a-summary/">Winning the Netflix Prize: A Summary</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/edwin-chen.html">Edwin Chen</a>
        </li>
        <li class="published" title="2011-10-24T04:15:00">
          on&nbsp;Mon 24 October 2011
        </li>

	</ul>

</div><!-- /.post-info -->
  <div class="entry-content"><p>How was the <a href="http://en.wikipedia.org/wiki/Netflix_Prize">Netflix Prize</a> won? I went through a lot of the Netflix Prize papers a couple years ago, so I&#8217;ll try to give an overview of the techniques that went into the winning solution here.</p>

  <h1>Normalization of Global Effects</h1>

  <p>Suppose Alice rates Inception 4 stars. We can think of this rating as composed of several parts:</p>

  <ul>
  <li>A <strong>baseline rating</strong> (e.g., maybe the mean over all user-movie ratings is 3.1 stars).</li>
  <li>An <strong>Alice-specific effect</strong> (e.g., maybe Alice tends to rate movies lower than the average user, so her ratings are -0.5 stars lower than we normally expect).</li>
  <li>An <strong>Inception-specific effect</strong> (e.g., Inception is a pretty awesome movie, so its ratings are 0.7 stars higher than we normally expect).</li>
  <li>A less predictable effect based on the <strong>specific interaction</strong> between Alice and Inception that accounts for the remainder of the stars (e.g., Alice really liked Inception because of its particular combination of Leonardo DiCaprio and neuroscience, so this rating gets an additional 0.7 stars).</li>
  </ul>


  <p>In other words, we&#8217;ve decomposed the 4-star rating into:
  4 = [3.1 (the baseline rating) - 0.5 (the Alice effect) + 0.7 (the Inception effect)] + 0.7 (the specific interaction)</p>

  <p>So instead of having our models predict the 4-star rating itself, we could first try to remove the effect of the baseline predictors (the first three components) and have them predict the specific 0.7 stars. (I guess you can also think of this as a simple kind of boosting.)</p>

  <p>More generally, additional baseline predictors include:</p>

  <ul>
  <li>A factor that allows Alice&#8217;s rating to (linearly) depend on the (square root of the) <strong>number of days since her first rating</strong>. (For example, have you ever noticed that you become a harsher critic over time?)</li>
  <li>A factor that allows Alice&#8217;s rating to depend on the <strong>number of days since the movie&#8217;s first rating by anyone</strong>. (If you&#8217;re one of the first people to watch it, maybe it&#8217;s because you&#8217;re a huge fan and really excited to see it on DVD, so you&#8217;ll tend to rate it higher.)</li>
  <li>A factor that allows Alice&#8217;s rating to depend on the <strong>number of people who have rated Inception</strong>. (Maybe Alice is a hipster who hates being part of the crowd.)</li>
  <li>A factor that allows Alice&#8217;s rating to <strong>depend on the movie&#8217;s overall rating</strong>.</li>
  <li>(Plus a bunch of others.)</li>
  </ul>


  <p>And, in fact, modeling these biases turned out to be fairly important: in their paper describing their final solution to the Netflix Prize, Bell and Koren write that</p>

  <blockquote><p>Of the numerous new algorithmic contributions, I would like to highlight one &#8211; those humble baseline predictors (or biases), which capture main effects in the data. While the literature mostly concentrates on the more sophisticated algorithmic aspects, we have learned that an accurate treatment of main effects is probably at least as signficant as coming up with modeling breakthroughs.</p></blockquote>


  <p>(For a perhaps more concrete example of why removing these biases is useful, suppose you know that Bob likes the same kinds of movies that Alice does. To predict Bob&#8217;s rating of Inception, instead of simply predicting the same 4 stars that Alice rated, if we know that Bob tends to rate movies 0.3 stars higher than average, then we could first remove Alice&#8217;s bias and then add in Bob&#8217;s: 4 + 0.5 + 0.3 = 4.8.)</p>

  <h1>Neighborhood Models</h1>

  <p>Let&#8217;s now look at some slightly more sophisticated models. As alluded to in the section above, one of the standard approaches to collaborative filtering is to use neighborhood models.</p>

  <p>Briefly, a neighborhood model works as follows. To predict Alice&#8217;s rating of Titanic, you could do two things:</p>

  <ul>
  <li><strong>Item-item approach</strong>: find a set of items similar to Titanic that Alice has also rated, and take the (weighted) mean of Alice&#8217;s ratings on them.</li>
  <li><strong>User-user approach</strong>: find a set of users similar to Alice who rated Titanic, and again take the mean of their ratings of Titanic.</li>
  </ul>


  <p>(See also my post on <a href="http://blog.echen.me/2011/02/15/an-overview-of-item-to-item-collaborative-filtering-with-amazons-recommendation-system/">item-to-item collaborative filtering on Amazon</a>.)</p>

  <p>The main questions, then, are (let&#8217;s stick to the item-item approach for simplicity):</p>

  <ul>
  <li>How do we find the set of similar items?</li>
  <li>How do we weight these items when taking their mean?</li>
  </ul>


  <p>The standard approach is to take some similarity metric (e.g., correlation or a Jaccard index) to define similarities between pairs of movies, take the K most similar movies under this metric (where K is perhaps chosen via cross-validation), and then use the same similarity metric when computing the weighted mean.</p>

  <p>This has a couple problems:</p>

  <ul>
  <li><strong>Neighbors aren&#8217;t independent</strong>, so using a standard similarity metric to define a weighted mean overcounts information. For example, suppose you ask five friends where you should eat tonight. Three of them went to Mexico last week and are sick of burritos, so they strongly recommend against a taqueria. Thus, your friends&#8217; recommendations have a stronger bias than what you&#8217;d get if you asked five friends who didn&#8217;t know each other at all. (Compare with the situation where all three Lord of the Rings Movies are neighbors of Harry Potter.)</li>
  <li>Different movies should perhaps be using <strong>different numbers of neighbors</strong>. Some movies may be predicted well by only one neighbor (e.g., Harry Potter 2 could be predicted well by Harry Potter 1 alone), some movies may require more, and some movies may have no good neighbors (so you should ignore your neighborhood algorithms entirely and let your other ratings models stand on their own).</li>
  </ul>


  <p>So another approach is the following:</p>

  <ul>
  <li>You can still use a similarity metric like correlation or cosine similarity to choose the set of similar items.</li>
  <li>But instead of using the similarity metric to define the interpolation weights in the mean calculations, you essentially perform a (sparse) <strong>linear regression to find the weights</strong> that minimize the squared error between an item&#8217;s rating and a linear combination of the ratings of its neighbors. Note that these weights are no longer constrained, so that if all neighbors are weak, then their weights will be close to zero and the neighborhood model will have a low effect.</li>
  </ul>


  <p>(A slightly more complicated user-user approach, similar to this item-item neighborhood approach, is also useful.)</p>

  <h1>Implicit Data</h1>

  <p>Adding on to the neighborhood approach, we can also let <strong>implicit data influence our predictions</strong>. The mere fact that a user rated lots of science fiction movies but no westerns, suggests that the user likes science fiction better than cowboys. So using a similar framework as in the neighborhood ratings model, we can learn for Inception a set of <strong>offset weights</strong> associated to Inception&#8217;s movie neighbors.</p>

  <p>Whenever we want to predict how Bob rates Inception, we look at whether Bob rated each of Inception&#8217;s neighbors. If he did, we add in the corresponding offset; if not, then we add nothing (and, thus, Bob&#8217;s rating is implicitly penalized by the missing weight).</p>

  <h1>Matrix Factorization</h1>

  <p>Complementing the neighborhood approach to collaborative filtering is the matrix factorization approach. Whereas the neighborhood approach takes a very local approach to ratings (if you liked Harry Potter 1, then you&#8217;ll like Harry Potter 2!), the factorization approach takes a more global view (we know that you like fantasy movies and that Harry Potter has a strong fantasy element, so we think that you&#8217;ll like Harry Potter) that <strong>decomposes users and movies into a set of latent factors</strong> (which we can think of as categories like &#8220;fantasy&#8221; or &#8220;violence&#8221;).</p>

  <p>In fact, matrix factorization methods were probably the most important class of techniques for winning the Netflix Prize. In their 2008 Progress Prize paper, Bell and Koren write</p>

  <blockquote><p>It seems that models based on matrix-factorization were found to be most accurate (and thus popular), as evident by recent publications and discussions on the Netflix Prize forum. We definitely agree to that, and would like to add that those matrix-factorization models also offer the important flexibility needed for modeling temporal effects and the binary view. Nonetheless, neighborhood models, which have been dominating most of the collaborative filtering literature, are still expected to be popular due to their practical characteristics - being able to handle new users/ratings without re-training and offering direct explanations to the recommendations.</p></blockquote>


  <p>The typical way to perform matrix factorizations is to perform a <strong>singular value decomposition</strong> on the (sparse) ratings matrix (using stochastic gradient descent and regularizing the weights of the factors, possibly constraining the weights to be positive to get a type of non-negative matrix factorization). (Note that this &#8220;SVD&#8221; is a little different from the standard SVD learned in linear algebra, since not every user has rated every movie and so the ratings matrix contains many missing elements that we don&#8217;t want to simply treat as 0.)</p>

  <p>Some SVD-inspired methods used in the Netflix Prize include:</p>

  <ul>
  <li><strong>Standard SVD</strong>: Once you&#8217;ve represented users and movies as factor vectors, you can dot product Alice&#8217;s vector with Inception&#8217;s vector to get Alice&#8217;s predicted rating of Inception.</li>
  <li><strong>Asymmetric SVD</strong>: Instead of users having their own notion of factor vectors, we can represent users as a bag of items they have rated (or provided implicit feedback for). So Alice is now represented as a (possibly weighted) sum of the factor vectors of the items she has rated, and to get her predicted rating of Titanic, we can dot product this  representation with the factor vector of Titanic. From a practical perspective, this model has an added benefit in that no user parameterizations are needed, so we can use this approach to generate recommendations as soon as a user provides some feedback (which could just be views or clicks on an item, and not necessarily ratings), without needing to retrain the model to factorize the user.</li>
  <li><strong>SVD++</strong>: Incorporate both the standard SVD and the asymmetric SVD model by representing users both by their own factor representation and as a bag of item vectors.</li>
  </ul>


  <h1>Regression</h1>

  <p>Some regression models were also used in the predictions. The models are fairly standard, I think, so I won&#8217;t spend too long here. Basically, just as with the neighborhood models, we can take a user-centric approach and a movie-centric approach to regression:</p>

  <ul>
  <li><strong>User-centric approach</strong>: We learn a regression model for each user, using all the movies that the user rated as the dataset. The response is the movie&#8217;s rating, and the predictor variables are attributes associated to that movie (which can be derived from, say, PCA, MDS, or an SVD).</li>
  <li><strong>Movie-centric approach</strong>: Similarly, we can learn a regression model for each movie, using all the users that rated the movie as the dataset.</li>
  </ul>


  <h1>Restricted Boltzmann Machines</h1>

  <p>Restricted Boltzmann Machines provide another kind of <strong>latent factor approach</strong> that can be used. See <a href="http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf">this paper</a> for a description of how to apply them to the Netflix Prize. (In case the paper&#8217;s a little difficult to read, I wrote an <a href="http://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines">introduction to RBMs</a> a little while ago.)</p>

  <h1>Temporal Effects</h1>

  <p>Many of the models incorporate temporal effects. For example, when describing the baseline predictors above, we used a few temporal predictors that allowed a user&#8217;s rating to (linearly) depend on the time since the first rating he ever made and on the time since a movie&#8217;s first rating. We can also get more fine-grained temporal effects by, say, binning items into a couple months&#8217; worth of ratings at a time, and allowing movie biases to change within each bin. (For example, maybe in May 2006, Time Magazine nominated Titanic as the best movie ever made, which caused a spurt in glowing ratings around that time.)</p>

  <p>In the matrix factorization approach, user factors were also allowed to be time-dependent (e.g., maybe Bob comes to like comedy movies more and more over time). We can also give more weight to recent user actions.</p>

  <h1>Regularization</h1>

  <p>Regularization was also applied throughout pretty much all the models learned, to <strong>prevent overfitting</strong> on the dataset. Ridge regression was heavily used in the factorization models to penalize large weights, and lasso regression (though less effective) was useful as well. Many other parameters (e.g., the baseline predictors, similarity weights and interpolation weights in the neighborhood models) were also estimated using fairly standard shrinkage techniques.</p>

  <h1>Ensemble Methods</h1>

  <p>Finally, let&#8217;s talk about how all of these different algorithms were combined to provide a single rating that <strong>exploits the strengths of each model</strong>. (Note that, as mentioned above, many of these models were not trained on the raw ratings data directly, but rather on the residuals of other models.)</p>

  <p>In the paper detailing their final solution, the winners describe using <strong>gradient boosted decision trees to combine over 500 models</strong>; previous solutions used instead a <strong>linear regression</strong> to combine the predictors.</p>

  <p>Briefly, gradient boosted decision trees work by sequentially fitting a series of decision trees to the data; each tree is asked to predict the error made by the previous trees, and is often trained on slightly perturbed versions of the data. (For a longer description of a similar technique, see <a href="http://blog.echen.me/2011/03/14/laymans-introduction-to-random-forests/">my introduction to random forests</a>.)</p>

  <p>Since GBDTs have a built-in ability to apply different methods to different slices of the data, we can add in some predictors that help the trees make useful clusterings:</p>

  <ul>
  <li>Number of movies each user rated</li>
  <li>Number of users that rated each movie</li>
  <li>Factor vectors of users and movies</li>
  <li>Hidden units of a restricted Boltzmann Machine</li>
  </ul>


  <p>(For example, one thing that Bell and Koren found (when using an earlier ensemble method) was that RBMs are more useful when the movie or the user has a low number of ratings, and that matrix factorization methods are more useful when the movie or user has a high number of ratings.)</p>

  <p>Here&#8217;s a graph of the effect of ensemble size from early on in the competition (in 2007), and the authors&#8217; take on it:</p>

  <p><a href="http://www2.research.att.com/~volinsky/netflix/newensemble.gif"><img src="http://www2.research.att.com/~volinsky/netflix/newensemble.gif" alt="Ensemble Size vs. RMSE" /></a></p>

  <blockquote><p>However, we would like to stress that it is not necessary to have such a large number of models to do well. The plot below shows RMSE as a function of the number of methods used. One can achieve our winning score (RMSE=0.8712) with less than 50 methods, using the best 3 methods can yield RMSE < 0.8800, which would land in the top 10. Even just using our single best method puts us on the leaderboard with an RMSE of 0.8890. The lesson here is that having lots of models is useful for the incremental results needed to win competitions, but practically, excellent systems can be built with just a few well-selected models.</p></blockquote>

  </div>  

                    </article>
 
<div class="paginator">
            <div class="navButton"> <a href="/category/misc.html" >Prev</a></div>
    <div class="navButton">Page 2 / 6</div>
        <div class="navButton"><a href="/category/misc3.html" >Next</a></div>
</div>
                </div>
            </aside><!-- /#featured -->
            
        
  
	      <div class="LaunchyardDetail">
	        <p>
	          <a class="title" href="/">Edwin Chen</a>
	          <br/>
	          Hanging. MIT, Microsoft Research, Clarium, Twitter, Google, Dropbox.
	          <br /><br />
            <a href="mailto:hello[at]echen.me">Email</a><br />
            <a href="https://twitter.com/#!/echen">Twitter</a><br/>
            <a href="https://github.com/echen">Github</a><br/>
            <a href="https://plus.google.com/113804726252165471503/">Google+</a><br/>
            <a href="http://www.linkedin.com/in/edwinchen1">LinkedIn</a><br/>
            <a href="http://quora.com/edwin-chen-1">Quora</a>
          </p>
          <br />
          <div id="recent_posts">
              <h3>Recent Posts</h3>
                <a href="/2013/01/08/improving-twitter-search-with-real-time-human-computation/">Improving Twitter Search with Real-Time Human Computation  </a><br /><br />
                <a href="/2012/07/31/edge-prediction-in-a-social-graph-my-solution-to-facebooks-user-recommendation-contest-on-kaggle/">Edge Prediction in a Social Graph: My Solution to Facebook's User Recommendation Contest on Kaggle  </a><br /><br />
                <a href="/2012/07/06/soda-vs-pop-with-twitter/">Soda vs. Pop with Twitter  </a><br /><br />
                <a href="/2012/04/25/making-the-most-of-mechanical-turk-tips-and-best-practices/">Making the Most of Mechanical Turk: Tips and Best Practices  </a><br /><br />
                <a href="/2012/03/20/infinite-mixture-models-with-nonparametric-bayes-and-the-dirichlet-process/">Infinite Mixture Models with Nonparametric Bayes and the Dirichlet Process  </a><br /><br />
                <a href="/2012/03/05/instant-interactive-visualization-with-d3-and-ggplot2/">Instant Interactive Visualization with d3 + ggplot2  </a><br /><br />
                <a href="/2012/02/09/movie-recommendations-and-more-via-mapreduce-and-scalding/">Movie Recommendations and More via MapReduce and Scalding  </a><br /><br />
                <a href="/2012/01/17/quick-introduction-to-ggplot2/">Quick Introduction to ggplot2  </a><br /><br />
                <a href="/2012/01/03/introduction-to-conditional-random-fields/">Introduction to Conditional Random Fields  </a><br /><br />
                <a href="/2011/10/24/winning-the-netflix-prize-a-summary/">Winning the Netflix Prize: A Summary  </a><br /><br />
            
          </div>
        </div>


        <section id="extras" >
       
        
        </section><!-- /#extras -->
	
        <footer id="contentinfo" >
                <address id="about" class="vcard ">
                Proudly powered by <a href="http://getpelican.com/" target="_blank">Pelican</a>, which takes
                great advantage of <a href="http://python.org" target="_blank">Python</a>.
		
                </address><!-- /#about -->
		

                
        </footer><!-- /#contentinfo -->

</body>
</html>